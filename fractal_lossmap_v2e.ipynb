{"cells":[{"cell_type":"markdown","metadata":{"id":"InosSXqlwUL4"},"source":["# Loading libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3-C8YNzAwKQx"},"outputs":[],"source":["# GPU settings\n","import os\n","os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=4'\n","# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,4'\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n","\n","\n","# Computation settings\n","import jax\n","from jax import lax, random, config, numpy as jnp\n","# config.update('jax_enable_x64', True)   # for double precision, but cannot run convolution!\n","\n","\n","import porespy as ps\n","import numpy as np\n","\n","# Plotting settings\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.animation as animation\n","from matplotlib import cm\n","\n","# ETC\n","import telegram\n","import pickle\n","import math\n","import datetime\n","from functools import partial\n","from typing import Callable, Any\n","from pprint import pprint\n","\n","from tqdm import tqdm\n","from datetime import datetime\n","from pytz import timezone\n","from collections import deque"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["# Model\n","target_dim = 10\n","num_epochs = 30\n","nonlinearity = 'relu'\n","num_blocks = (3, 3, 3)\n","c_hidden = (16, 32, 64)\n","\n","# Datset\n","batch_size = 1000\n","default_outer_batch_size = 32\n","\n","# Plotting\n","default_resolution = 4\n","mnmx = [-4, -0, -4, -0]\n","dpi = 100\n","figsize = (16, 8)\n","interactive_gui = True"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["\n","record_t = datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d_%H%M')[2:]\n","TOKEN = '6740952693:AAFOUwNFVu2O3Bpf7nlKwIlDzyNaarN7Fl8'\n","CHAT_ID = '5110804803'\n","msg = f\"Lossmap was generated!\\nPlease check and zoom it!\"\n","\n","bot = telegram.Bot(TOKEN)\n","\n","def canonical_name(num_blocks=num_blocks, record_t=record_t):\n","    return f\"ResNet-{sum(num_blocks)*2+2}_{record_t}\"\n","\n","def send_alram(msg=msg):\n","    return bot.sendMessage(chat_id=CHAT_ID, text=msg)\n","\n","if interactive_gui:\n","    ## interactive plotting\n","    # from google.colab import output\n","    # output.enable_custom_widget_manager()\n","    %matplotlib ipympl\n","else:\n","    matplotlib.use('Agg')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"S8gcL3ntLx46"},"outputs":[],"source":["# Make the save directory\n","from datetime import datetime\n","from pytz import timezone\n","import json\n","\n","record_t = datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d%H%M%S')[2:]\n","output_path = f\"./output/{canonical_name()}\"\n","os.makedirs(output_path + \"/train\", exist_ok=True)\n","os.makedirs(output_path + \"/test\", exist_ok=True)\n","\n","# metadata\n","metadata = {\n","    'model_hyperparams': {\n","        'layers': sum(num_blocks)*2+2,\n","        'num_blocks': num_blocks,\n","        'c_hidden': c_hidden,\n","        'num_epochs': num_epochs,\n","        'batch_size': batch_size,\n","        'activation': nonlinearity,\n","    },\n","    'plot_hyperparams': {\n","        'resolution': default_resolution,\n","        'initial_bound': mnmx,\n","    },\n","    'recording(UTC+9)': record_t\n","}\n","\n","with open(f'{output_path}/metadata.json', 'w') as md:\n","    json.dump(metadata, md, indent=4)"]},{"cell_type":"markdown","metadata":{"id":"36XJLykLBgzk"},"source":["# Modeling"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[{"data":{"text/html":["<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[15:20:46] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> From                                                                      <a href=\"file://c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\tensorflow\\python\\util\\module_wrapper.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">module_wrapper.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file://c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\tensorflow\\python\\util\\module_wrapper.py#149\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">149</span></a>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\keras\\src\\los <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         ses.py:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2976</span>: The name tf.losses.sparse_softmax_cross_entropy is           <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>         instead.                                                                  <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n","<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">           </span>                                                                                   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">                     </span>\n","</pre>\n"],"text/plain":["\u001b[2;36m[15:20:46]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m From                                                                      \u001b]8;id=25702;file://c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\tensorflow\\python\\util\\module_wrapper.py\u001b\\\u001b[2mmodule_wrapper.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=526886;file://c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\tensorflow\\python\\util\\module_wrapper.py#149\u001b\\\u001b[2m149\u001b[0m\u001b]8;;\u001b\\\n","\u001b[2;36m           \u001b[0m         c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\keras\\src\\los \u001b[2m                     \u001b[0m\n","\u001b[2;36m           \u001b[0m         ses.py:\u001b[1;36m2976\u001b[0m: The name tf.losses.sparse_softmax_cross_entropy is           \u001b[2m                     \u001b[0m\n","\u001b[2;36m           \u001b[0m         deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy   \u001b[2m                     \u001b[0m\n","\u001b[2;36m           \u001b[0m         instead.                                                                  \u001b[2m                     \u001b[0m\n","\u001b[2;36m           \u001b[0m                                                                                   \u001b[2m                     \u001b[0m\n"]},"metadata":{},"output_type":"display_data"}],"source":["from datasets.mnist import *\n","\n","train_ds = data_normalize(train_ds).shuffle(buffer_size=10, seed=42).batch(batch_size).prefetch(1)\n","test_ds = data_normalize(test_ds).shuffle(buffer_size=10, seed=42).batch(batch_size).prefetch(1)\n","\n","total_batch = train_ds.cardinality().numpy()\n","total_tbatch = test_ds.cardinality().numpy()\n","\n","for batch in train_ds.as_numpy_iterator():\n","    x = batch['image']\n","    y = batch['label']\n","    break\n","\n","# def shard_data(data, n_devices):\n","#     data = data.reshape(n_devices, data.shape[0] // n_devices, *data.shape[1:])\n","#     return data\n","\n","# shard_data(x, 4).shape"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["from model.resnet_v3 import *\n","import os\n","\n","resnet = ResNet(num_classes=target_dim, act_fn=nn.relu, block_class=ResNetBlock, num_blocks=num_blocks, c_hidden=c_hidden)\n","\n","\n","# Exporting the NN-Graph\n","resnet20 = ResNet(10, nn.relu, ResNetBlock)\n","variables = resnet20.init(jax.random.PRNGKey(1), x)\n","# applied = partial(resnet20.apply, variables, mutable=['batch_stats'])\n","# xla = jax.xla_computation(applied)(x)\n","\n","# with open(f\"{output_path}/arch.dot\", 'w') as f:\n","#     print(\"Printing...\")\n","#     f.write(xla.as_hlo_dot_graph())\n","#     print('Drawing... It takes few seconds...')\n","#     os.system(f'dot {output_path}/arch.dot -Tpng > {output_path}/arch.png')\n","#     print(\"Done!\")"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["# from model.shallownet import *\n","from plot.trendline import plot_trend\n","from collections import deque\n","\n","def split_and_train(resnet, hparams, batches, tbatches, num_epochs):\n","    global tile_batch, zoom_seq\n","    global loss_deque, tloss_deque, acc_deque, tacc_deque, minloss_global\n","\n","    # Cut off the learning rates as bite size\n","    bs = hparams.shape[0]\n","    if bs > default_outer_batch_size:\n","        train_loss1, test_loss1 = split_and_train(resnet, hparams[:bs//2, ], batches, tbatches, num_epochs)\n","        train_loss2, test_loss2 = split_and_train(resnet, hparams[bs//2:, ], batches, tbatches, num_epochs)\n","        return jnp.concatenate((train_loss1, train_loss2), axis=0), jnp.concatenate((test_loss1, test_loss2), axis=0)\n","\n","    # variables, copied\n","    variables = initialize(resnet, 42, x)\n","    variables = jax.tree_map(lambda x: jnp.tile(x, (bs,)+(1,)*len(x.shape)), variables)\n","\n","    ### tree_map\n","    # apply each other offset and learning rate\n","    tile_batch += 1\n","    desc = f'[Tile {tile_batch}/{math.ceil(default_resolution**2/default_outer_batch_size)}] Training-epochs: '\n","    loss_archive, acc_archive, tloss_archive, tacc_archive = train_on_the_track(variables, batches, tbatches, hparams, num_epochs, desc=desc)\n","\n","    # TOP5 ranking\n","    def min_tournament(loss_archive):\n","        loss_arr = np.array(loss_archive).T\n","        minloss = loss_arr[:, -20:].mean(axis=1)\n","        px_minloss = minloss.argmin()\n","        minloss = minloss.min()\n","        return px_minloss, minloss\n","\n","    # Find the well-converged train loss and get them up!\n","    px_minloss, minloss = min_tournament(loss_archive)\n","    loss_arr = np.array(loss_archive).T\n","    acc_arr = np.array(acc_archive).T\n","    tloss_arr = np.array(tloss_archive).T\n","    tacc_arr = np.array(tacc_archive).T\n","\n","    if minloss_global > minloss:\n","        minloss_global = minloss\n","        px = (tile_batch - 1) * default_outer_batch_size + px_minloss\n","        loss_deque.appendleft({f\"{px}\": loss_arr[px_minloss]})\n","        acc_deque.appendleft({f\"{px}\": acc_arr[px_minloss]})\n","        tloss_deque.appendleft({f\"{px}\": tloss_arr[px_minloss]})\n","        tacc_deque.appendleft({f\"{px}\": tacc_arr[px_minloss]})\n","    \n","\n","    return convergence_measure(jnp.stack(loss_archive, axis=-1)), convergence_measure(jnp.stack(tloss_archive, axis=-1))    # stack-->(16, 100), convergence_measure-->(...?)\n","\n","\n","# Compensator\n","@partial(jax.vmap, in_axes=(0,), out_axes=0)\n","def convergence_measure(v, max_val=1e6):\n","    fin = jnp.isfinite(v)\n","    v = v * fin + max_val * (1-fin)\n","    v /= v[0]\n","    exceeds = (v > max_val)\n","    v = v * (1-exceeds) + max_val * exceeds\n","    # converged = (jnp.mean(v[-20:]) < 1)\n","    \n","    return -(1-jnp.mean(v))\n"]},{"cell_type":"markdown","metadata":{"id":"szLdaCvzhItA"},"source":["# Plotting and Measure the Fractal Dimension"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"GxkGz1-whK3-"},"outputs":[],"source":["# Generate the lossmap\n","def gen_img(mnmx, resolution=None):\n","    \"\"\"\n","    generate an image of the hyperparameter landscape,\n","    for a range of hyperparameter values specified by mnmx\n","    \"\"\"\n","    global zoom_seq, loss_deque, tloss_deque, acc_deque, tacc_deque, minloss_global\n","\n","    loss_deque = deque(maxlen=5)\n","    tloss_deque = deque(maxlen=5)\n","    acc_deque = deque(maxlen=5)\n","    tacc_deque = deque(maxlen=5)\n","\n","    minloss_global = np.float32('inf')\n","\n","    if resolution is None:\n","        resolution = default_resolution\n","\n","    mn1, mx1, mn2, mx2 = mnmx\n","    gg1 = jnp.logspace(mn1, mx1, resolution)\n","    gg2 = jnp.logspace(mn2, mx2, resolution)\n","    lr0, lr1 = jnp.meshgrid(gg2, gg1)\n","    lr = jnp.stack([lr0.ravel(), lr1.ravel()], axis=-1)\n","\n","    V, tV = split_and_train(\n","        resnet=resnet,\n","        hparams=lr,\n","        batches=train_ds,\n","        tbatches=test_ds,\n","        num_epochs=num_epochs\n","        )\n","    \n","    # plot the loss trend\n","    plot_trend(loss_deque, ylabel='Loss', saveas=f'{output_path}/train/convTOP5_loss_zoom{zoom_seq}.png')\n","    plot_trend(acc_deque, ylabel='Acc', saveas=f'{output_path}/train/convTOP5_acc_zoom{zoom_seq}.png')\n","    plot_trend(tloss_deque, ylabel='Loss', saveas=f'{output_path}/test/convTOP5_vloss_zoom{zoom_seq}.png')\n","    plot_trend(tacc_deque, ylabel='Acc', saveas=f'{output_path}/test/convTOP5_vacc_zoom{zoom_seq}.png')\n","\n","    V = V.reshape((resolution, resolution))\n","    tV = tV.reshape((resolution, resolution))\n","\n","    send_alram(msg=msg)\n","\n","\n","    return V, tV\n","\n","\n","# Measure the fractal dim\n","def extract_edges(X):\n","    \"\"\"\n","    define edges as sign changes in the scalar representing convergence or\n","    divergence rate -- on one side of the edge training converges,\n","    while on the other side of the edge training diverges\n","    \"\"\"\n","\n","    Y = jnp.stack((X[1:,1:], X[:-1,1:], X[1:,:-1], X[:-1,:-1]), axis=-1)\n","    Z = jnp.sign(jnp.max(Y, axis=-1)*jnp.min(Y, axis=-1))\n","    return Z<0\n","\n","def estimate_fractal_dimension(hist_video, show_plot=True, saveas=None):\n","    if show_plot:\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4), constrained_layout=True)\n","        ax1.set_yscale('log')\n","        ax1.set_xscale('log')\n","        ax1.set_xlabel('box edge length')\n","        ax1.set_ylabel('number of boxes spanning phases')\n","        ax2.set_xlabel('box edge length')\n","        ax2.set_ylabel('slope')\n","        ax2.set_xscale('log')\n","\n","    mfds = []\n","    for n, U in enumerate(hist_video):\n","        edge = extract_edges(U[0])\n","        bc = ps.metrics.boxcount(edge)\n","        mfd = np.median(bc.slope)\n","        mfds.append(mfd)\n","        print(f'Median fractal dimension: {mfd} at zoom{n}')\n","\n","        if show_plot:\n","            ax1.plot(bc.size, bc.count, '-o', alpha=0.7, label=f'Zoom{n}, mfd={mfd:.3f}')\n","            ax2.plot(bc.size, bc.slope, '-o', alpha=0.7, label=f'Zoom{n}, mfd={mfd:.3f}')\n","    \n","    if saveas:\n","        plt.legend()\n","        plt.savefig(saveas)\n","\n","    return mfds\n","\n","# Interploating\n","def cdf_img(x, x_ref, buffer=0.25):\n","    \"\"\"\n","    rescale x, relative to x_ref (x_ref is often the same as x), to achieve a uniform\n","    distribution over values with positive and negative intensities, but also to\n","    preserve the sign of x. This makes for a visualization that shows more\n","    structure.\n","    \"\"\"\n","    u = jnp.sort(x_ref.ravel())\n","    num_neg = jnp.sum(u<0)\n","    num_nonneg = u.shape[0] - num_neg\n","    v = jnp.concatenate((jnp.linspace(-1,-buffer,num_neg), jnp.linspace(buffer,1,num_nonneg)), axis=0)\n","    y = jnp.interp(x, u, v)\n","    return -y\n","\n","\n","# Notation\n","def truncate_sci_notation(numbers):\n","    \"\"\"\n","    keeping enough significant digits that the\n","    numbers disagree in four digits\n","    \"\"\"\n","\n","    # Convert numbers to scientific notation\n","    n1_sci, n2_sci = \"{:.15e}\".format(numbers[0]), \"{:.15e}\".format(numbers[1])\n","\n","    # Extract the significant parts and exponents\n","    sig_n1, exp_n1 = n1_sci.split('e')\n","    sig_n2, exp_n2 = n2_sci.split('e')\n","\n","    # Find the first position at which they disagree\n","    min_len = min(len(sig_n1), len(sig_n2))\n","    truncate_index = min_len\n","\n","    for i in range(min_len):\n","        if (sig_n1[i] != sig_n2[i]) or (exp_n1 != exp_n2):\n","            # +4 accounts for 4 digits after the first disagreement\n","            truncate_index = i + 4\n","            if i == 0:\n","                truncate_index += 1 # Account for decimal point\n","        break\n","\n","    exp_n1 = exp_n1[0] + exp_n1[2]\n","    exp_n2 = exp_n2[0] + exp_n2[2]\n","    if (exp_n1 == \"+00\") and (exp_n2 == \"+00\"):\n","        # don't bother with scientific notation if exponent is 0\n","        return [sig_n1[:truncate_index], sig_n2[:truncate_index]]\n","\n","    # Truncate and reconstruct the scientific notation\n","    truncated_n1 = \"{}e{}\".format(sig_n1[:truncate_index], exp_n1)\n","    truncated_n2 = \"{}e{}\".format(sig_n2[:truncate_index], exp_n2)\n","\n","    return [truncated_n1, truncated_n2]\n","\n","def tickslabels(mnmx):\n","    return mnmx, truncate_sci_notation(10.**np.array(mnmx))"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"MrJfi2LYjceH"},"outputs":[],"source":["# Animating zoom sequences and interpolating between frames\n","def zoom_out_sequence(hist_final, growth_factor=2., max_scale=6):\n","  \"\"\"\n","  generate a sequence of (image, bounds) zooming out from the (image, bounds) in hist_final\n","  \"\"\"\n","\n","  image, mnmx = hist_final\n","\n","  cT = np.array([(mnmx[0] + mnmx[1])/2., (mnmx[2] + mnmx[3])/2.])\n","  wT = np.array([mnmx[1] - mnmx[0], mnmx[3] - mnmx[2]])\n","\n","  hist = [(image, mnmx)]\n","  w_scale = 1.\n","  while np.min(wT * w_scale) < max_scale:\n","    w_scale *= 2\n","    mnmx = [\n","        cT[0] - w_scale * wT[0]/2.,\n","        cT[0] + w_scale * wT[0]/2.,\n","        cT[1] - w_scale * wT[1]/2.,\n","        cT[1] + w_scale * wT[1]/2.,\n","    ]\n","    hist.insert(0, (np.zeros((2,2)), mnmx))\n","\n","  return hist\n","\n","def increase_resolution(history, target_res):\n","  \"\"\"\n","  Increase the resolution of images of a fractal landscape that we've already\n","  generated.\n","\n","  Find the first entry in history with resolution below target_res, and increase\n","  its resolution. If all images are already at least the target resolution,\n","  return False.\n","  \"\"\"\n","\n","  new_h = []\n","  for ii in range(len(history)):\n","    h = history[ii]\n","    image, mnmx = h\n","    if image.shape[0] < target_res:\n","      current_time = datetime.datetime.now()\n","      print( f\"increasing resolution of {ii} / {len(history)} at {current_time}, current resolution is {image.shape}\")\n","      image = gen_img(mnmx, resolution=target_res)\n","      history[ii] = (image, mnmx)\n","      return True\n","  return False\n","\n","def interpolate_history(hist1, hist2, alpha):\n","  \"\"\"\n","  get the mnmx (hyperparameter bounding box) value for a fraction alpha between\n","  two images\n","  \"\"\"\n","\n","  _, mnmx1 = hist1\n","  _, mnmx2 = hist2\n","\n","  if alpha == 0:\n","    # avoid NaNs on very last frame\n","    return mnmx1\n","\n","  w1 = np.array([mnmx1[1] - mnmx1[0], mnmx1[3] - mnmx1[2]])\n","  w2 = np.array([mnmx2[1] - mnmx2[0], mnmx2[3] - mnmx2[2]])\n","  c1 = np.array([(mnmx1[0] + mnmx1[1])/2, (mnmx1[2] + mnmx1[3])/2])\n","  c2 = np.array([(mnmx2[0] + mnmx2[1])/2, (mnmx2[2] + mnmx2[3])/2])\n","\n","  gamma = np.exp((1-alpha)*0 + alpha*np.log(w2/w1))\n","\n","  # ct = cstar + (c1 - cstar)*gamma\n","  # c1 = cstar + (c1 - cstar)*1\n","  # c2 = cstar + (c1 - cstar)*w2/w1\n","  cstar = (c2 - c1*w2/w1) / (1 - w2 / w1)\n","\n","  ct = cstar + (c1 - cstar)*gamma\n","  hwt = gamma*w1\n","\n","  return [ct[0] - hwt[0]/2, ct[0] + hwt[0]/2, ct[1] - hwt[1]/2, ct[1] + hwt[1]/2]\n","\n","\n","def em(extent_rev):\n","  return [extent_rev[2], extent_rev[3], extent_rev[0], extent_rev[1]]\n","\n","def make_animator(history, timesteps_per_transition=60, reference_scale=None, cmap='Spectral'):\n","\n","  fig, ax, im1 = show_img(history[0][0], history[0][1], newmnmx=None,\n","                          handler=False, reference_scale=reference_scale, cmap=cmap)\n","\n","  im2 = ax.imshow(\n","      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n","      vmin = -1, vmax = 1,\n","      cmap=cmap,\n","      aspect='auto',\n","      interpolation='nearest'\n","      )\n","\n","  im3 = ax.imshow(\n","      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n","      vmin = -1, vmax = 1,\n","      cmap=cmap,\n","      aspect='auto',\n","      interpolation='nearest'\n","      )\n","\n","  def animate(n):\n","    hist_index = n // timesteps_per_transition\n","    alpha = (n % timesteps_per_transition) / timesteps_per_transition\n","\n","    hist1 = history[hist_index]\n","    if hist_index >= len(history)-1:\n","      hist2 = hist1 # very last frame\n","    else:\n","      hist2 = history[hist_index+1]\n","    if hist_index >= len(history)-2:\n","      hist3 = hist2 # very last frame\n","    else:\n","      hist3 = history[hist_index+2]\n","\n","    lims = interpolate_history(hist1, hist2, alpha)\n","\n","    # interpolation scheme for image restretch / colormap\n","    alpha_area = jnp.sin(alpha*np.pi/2)**2\n","\n","    print(f'frame {n} / {timesteps_per_transition*len(history)}, zoom step {hist_index} / {len(history)}', end='\\r', flush=True)\n","\n","    img_1 = (1-alpha_area)*cdf_img(hist1[0], hist1[0]) + alpha_area*cdf_img(hist1[0], hist2[0])\n","    img_2 = (1-alpha_area)*cdf_img(hist2[0], hist1[0]) + alpha_area*cdf_img(hist2[0], hist2[0])\n","    img_3 = (1-alpha_area)*cdf_img(hist3[0], hist1[0]) + alpha_area*cdf_img(hist3[0], hist2[0])\n","\n","    im1.set_data(img_1)\n","    im1.set_extent(em(hist1[1]))\n","    im2.set_data(img_2)\n","    im2.set_extent(em(hist2[1]))\n","    im3.set_data(img_3)\n","    im3.set_extent(em(hist3[1]))\n","    im3.set_alpha(alpha)\n","\n","    ax.set_ylim(lims[0], lims[1])\n","    ax.set_xlim(lims[2], lims[3])\n","\n","    # Set the new tick positions\n","    ax.set_xticks(*tickslabels([lims[2], lims[3]]))\n","    ax.set_yticks(*tickslabels([lims[0], lims[1]]), rotation=90)\n","\n","    labels = ax.get_xticklabels()\n","    labels[0].set_horizontalalignment('left')\n","    labels[1].set_horizontalalignment('right')\n","    labels = ax.get_yticklabels()\n","    labels[0].set_verticalalignment('bottom')\n","    labels[1].set_verticalalignment('top')\n","\n","    return fig,\n","\n","  anim = animation.FuncAnimation(fig,animate,frames=timesteps_per_transition*(len(history)-1)+1, repeat=False)\n","  return anim"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"4rKdJxPsUfnF"},"outputs":[],"source":["# Interactive plotting\n","cids = []\n","click_event = [None]\n","\n","def onclick(event):\n","    click_event[0] = (event.xdata, event.ydata)\n","\n","def onrelease(event, fig, im, rect, mnmx, img, recalculate_image=True):\n","    global tile_batch, zoom_seq\n","    tile_batch = 0\n","    zoom_seq += 1\n","    \n","    if click_event[0] is None:\n","        return\n","\n","    e0 = [click_event[0][0], event.xdata]\n","    e1 = [click_event[0][1], event.ydata]\n","\n","    for v in e0+e1:\n","        if v is None:\n","            return\n","\n","    newmnmx = [np.min(e1), np.max(e1), np.min(e0), np.max(e0)]\n","\n","    min_w = (mnmx[1] - mnmx[0])/20\n","    if newmnmx[1] - newmnmx[0] < min_w:\n","        c = (newmnmx[1] + newmnmx[0])/2.\n","        newmnmx[0] = c - min_w/2\n","        newmnmx[1] = c + min_w/2\n","    min_w = (mnmx[3] - mnmx[2])/20\n","\n","    if newmnmx[1] - newmnmx[0] < min_w:\n","        c = (newmnmx[3] + newmnmx[2])/2.\n","        newmnmx[2] = c - min_w/2\n","        newmnmx[3] = c + min_w/2\n","\n","    for v in newmnmx:\n","        if v is None:\n","            return\n","\n","    plot_img(img, mnmx, newmnmx, fig=fig, im=im, rect=rect)\n","    plt.draw()\n","\n","    if recalculate_image:\n","        click_event[0] = None\n","        mnmx = newmnmx\n","        img = gen_img(mnmx)\n","        plot_img(img, mnmx, None, fig=fig, im=im, rect=rect)\n","\n","\n","def plot_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n","             handler=True, savename=None,\n","             reference_scale=None,\n","             cmap='Spectral',\n","             title=\"\"\n","             ):\n","\n","    global loss_deque, acc_deque, tloss_deque, tacc_deque, default_outer_batch_size\n","\n","    mn1, mx1, mn2, mx2 = mnmx\n","    trainimg, testimg = image\n","\n","    if reference_scale is None:\n","        reference_scale_train = trainimg\n","        reference_scale_test = testimg\n","\n","\n","    trainimg = cdf_img(trainimg, reference_scale_train)\n","    testimg = cdf_img(testimg, reference_scale_test)\n","\n","    # ax1 = None\n","    if im is not None:\n","        im1, im2 = im\n","\n","    if fig is None:\n","        # fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi, sharey=True, constrained_layout=True)\n","        fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi, sharey=True)\n","\n","        ax = ax.flatten()\n","        im1 = ax[0].imshow(trainimg,\n","                        extent=[mn2, mx2, mn1, mx1],\n","                        origin='lower',\n","                        vmin=-1, vmax=1,\n","                        cmap=cmap,\n","                        aspect='auto',\n","                        interpolation='nearest'\n","                        )\n","        im2 = ax[1].imshow(testimg,\n","                        extent=[mn2, mx2, mn1, mx1],\n","                        origin='lower',\n","                        vmin=-1, vmax=1,\n","                        cmap=cmap,\n","                        aspect='auto',\n","                        interpolation='nearest'\n","                        )\n","        # fig.colorbar(im1, ax=ax.ravel().tolist())\n","        if title == \"\":\n","            batch_text = f\"{num_epochs} epochs, {batch_size} batches\"\n","            title = f'Trainability dependence on parameter initialization and learning rates'\n","        fig.suptitle(title)\n","\n","        fig.supxlabel('Input layer weight offset')\n","        fig.supylabel('Learning rate')\n","\n","        rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","        ax[0].add_patch(rect)\n","        rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","        ax[1].add_patch(rect)\n","\n","    im1.set_extent([mn2, mx2, mn1, mx1])\n","    im1.set_data(trainimg)\n","    im2.set_extent([mn2, mx2, mn1, mx1])\n","    im2.set_data(testimg)\n","\n","    # Set the new tick positions on the x-axis\n","    # aaxx = plt.gca()\n","    ax = fig.axes\n","    ax[0].set_title(\"Training Lossmap\")\n","    ax[1].set_title(\"Evaluating Lossmap\")\n","\n","    for nn, aaxx in enumerate(ax):\n","        aaxx.set_xticks(*tickslabels([mn2, mx2]))\n","        aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n","\n","        labels = aaxx.get_xticklabels()\n","        labels[0].set_horizontalalignment('left')\n","        labels[1].set_horizontalalignment('right')\n","        if nn == 0:\n","            labels = aaxx.get_yticklabels()\n","            labels[0].set_verticalalignment('bottom')\n","            labels[1].set_verticalalignment('top')\n","\n","    if handler and (newmnmx is None):\n","        trainimg_history.append((trainimg, mnmx))\n","        testimg_history.append((testimg, mnmx))\n","\n","\n","    if newmnmx:\n","        mn1, mx1, mn2, mx2 = newmnmx\n","    rect.set_xy((mn2, mn1))\n","    rect.set_width(mx2-mn2)\n","    rect.set_height(mx1-mn1)\n","\n","    if handler:\n","        while len(cids) > 0:\n","            fig.canvas.mpl_disconnect(cids.pop())\n","\n","    def onrelease_partial(event):\n","        return onrelease(event, fig, im, rect, mnmx, img)\n","    def onmotion_partial(event):\n","        return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n","\n","    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n","    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n","    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n","\n","    # plt.tight_layout()\n","\n","    im = (im1, im2)\n","    plt.draw()\n","\n","    if savename:\n","        plt.savefig(savename)\n","\n","    # Star-patch\n","    for rank, px in enumerate(loss_deque):\n","        patch_coord = [(int(k) % default_resolution, int(k) // default_resolution) for k, _ in px.items()][0]\n","        ax[0].text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax[0].transAxes)\n","        ax[1].text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax[1].transAxes)\n","\n","\n","    return fig, ax, im\n","\n","\n","def increase_resolution(train_history, test_history, target_res):\n","  \"\"\"\n","  Increase the resolution of images of a fractal landscape that we've already\n","  generated.\n","\n","  Find the first entry in history with resolution below target_res, and increase\n","  its resolution. If all images are already at least the target resolution,\n","  return False.\n","  \"\"\"\n","\n","  new_h = []\n","  for ii in range(len(train_history)):\n","    train_h = train_history[ii]\n","    test_h = test_history[ii]\n","\n","    train_image, train_mnmx = train_h\n","    test_image, test_mnmx = test_h\n","\n","    if train_image.shape[0] < target_res:\n","      current_time = datetime.now()\n","      print( f\"increasing resolution of {ii} / {len(train_history)} at {current_time}, current resolution is {train_image.shape}\")\n","      train_image, test_image = gen_img(train_mnmx, resolution=target_res)\n","      train_history[ii] = (train_image, train_mnmx)\n","      test_history[ii] = (test_image, test_mnmx)\n","\n","      return True\n","  return False\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"RLsWZXMIpeQZ"},"outputs":[],"source":["def show_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n","             handler=True, savename=None,\n","             reference_scale=None,\n","             cmap='Spectral_r',\n","             title=\"\"\n","             ):\n","  \n","  global loss_deque, acc_deque, tloss_deque, tacc_deque, default_outer_batch_size\n","  \n","  mn1, mx1, mn2, mx2 = mnmx\n","\n","  if reference_scale is None:\n","    reference_scale = image\n","\n","  image = cdf_img(image, reference_scale)\n","\n","  ax1 = None\n","  if fig is None:\n","    fig, (ax1) = plt.subplots(figsize=(figsize[0]/2, figsize[1]), dpi=dpi)\n","    im = ax1.imshow(image,\n","                    extent=[mn2, mx2, mn1, mx1],\n","                    origin='lower',\n","                    vmin=-1, vmax=1,\n","                    cmap=cmap,\n","                    aspect='auto',\n","                    interpolation='nearest'\n","                    )\n","    fig.colorbar(im, ax=ax1)\n","\n","    if title == \"\":\n","      batch_text = f\"{num_epochs} epochs, {batch_size} batches\"\n","      title = 'Trainability dependence on parameter initialization and learning rates'\n","    fig.suptitle(title)\n","   \n","    ax1.set_ylabel('Learning rate')\n","    ax1.set_xlabel('Input layer weight offset')\n","\n","    rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","    ax1.add_patch(rect)\n","\n","  im.set_extent([mn2, mx2, mn1, mx1])\n","  im.set_data(image)\n","\n","  # Set the new tick positions on the x-axis\n","  aaxx = plt.gca()\n","  aaxx.set_xticks(*tickslabels([mn2, mx2]))\n","  aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n","\n","  labels = aaxx.get_xticklabels()\n","  labels[0].set_horizontalalignment('left')\n","  labels[1].set_horizontalalignment('right')\n","  labels = aaxx.get_yticklabels()\n","  labels[0].set_verticalalignment('bottom')\n","  labels[1].set_verticalalignment('top')\n","\n","  if handler and (newmnmx is None):\n","    image_history.append((image, mnmx))\n","\n","  if newmnmx:\n","    mn1, mx1, mn2, mx2 = newmnmx\n","  rect.set_xy((mn2, mn1))\n","  rect.set_width(mx2-mn2)\n","  rect.set_height(mx1-mn1)\n","\n","  if handler:\n","    while len(cids) > 0:\n","      fig.canvas.mpl_disconnect(cids.pop())\n","\n","    def onrelease_partial(event):\n","      return onrelease(event, fig, im, rect, mnmx, img)\n","    def onmotion_partial(event):\n","      return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n","\n","    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n","    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n","    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n","\n","  # plt.tight_layout()\n","  plt.draw()\n","\n","  if savename:\n","    plt.savefig(savename)\n","  \n","  for rank, px in enumerate(loss_deque):\n","    patch_coord = [(int(k) % default_resolution, int(k) // default_resolution) for k, _ in px.items()][0]\n","    ax1.text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax1.transAxes)\n","  savename_marked = savename.split('.')\n","  savename_marked[1] = savename_marked[1] + \"_starred\"\n","  savename_marked = \".\".join(savename_marked)\n","  plt.savefig(savename_marked)\n","  \n","\n","  return fig, ax1, im"]},{"cell_type":"markdown","metadata":{"id":"esuAL5tAit2N"},"source":["# Generating the lossmap"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":94382,"status":"error","timestamp":1711987939194,"user":{"displayName":"J U","userId":"09528049220557542940"},"user_tz":-540},"id":"H3r5KDHEhEeu","outputId":"5eb04283-2918-49e5-88ad-e9f48c8c0345"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\konyang\\AppData\\Local\\Temp\\ipykernel_27536\\1772814733.py:11: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n","  send_alram(msg=f\"Start training.\\n{canonical_name()}\")\n","RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n","                                                                  \r"]},{"ename":"ValueError","evalue":"axis 3 is out of bounds for array of dimension 3","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[12], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m trainimg_history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m testimg_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mgen_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnmx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mion()\n","Cell \u001b[1;32mIn[8], line 25\u001b[0m, in \u001b[0;36mgen_img\u001b[1;34m(mnmx, resolution)\u001b[0m\n\u001b[0;32m     22\u001b[0m lr0, lr1 \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmeshgrid(gg2, gg1)\n\u001b[0;32m     23\u001b[0m lr \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mstack([lr0\u001b[38;5;241m.\u001b[39mravel(), lr1\u001b[38;5;241m.\u001b[39mravel()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 25\u001b[0m V, tV \u001b[38;5;241m=\u001b[39m \u001b[43msplit_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# plot the loss trend\u001b[39;00m\n\u001b[0;32m     34\u001b[0m plot_trend(loss_deque, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m, saveas\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train/convTOP5_loss_zoom\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzoom_seq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[1;32mIn[7], line 24\u001b[0m, in \u001b[0;36msplit_and_train\u001b[1;34m(resnet, hparams, batches, tbatches, num_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m tile_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     23\u001b[0m desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Tile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtile_batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmath\u001b[38;5;241m.\u001b[39mceil(default_resolution\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mdefault_outer_batch_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training-epochs: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 24\u001b[0m loss_archive, acc_archive, tloss_archive, tacc_archive \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_the_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# TOP5 ranking\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin_tournament\u001b[39m(loss_archive):\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v3.py:193\u001b[0m, in \u001b[0;36mtrain_on_the_track\u001b[1;34m(variables, batches, tbatches, hparams, epochs, desc)\u001b[0m\n\u001b[0;32m    190\u001b[0m variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m params\n\u001b[0;32m    192\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), total\u001b[38;5;241m=\u001b[39mepochs, desc\u001b[38;5;241m=\u001b[39mdesc, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 193\u001b[0m     loss, acc, tloss, tacc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate_oneEpoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m     loss_archive\u001b[38;5;241m.\u001b[39mappend(loss)\n\u001b[0;32m    195\u001b[0m     acc_archive\u001b[38;5;241m.\u001b[39mappend(acc)\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v3.py:221\u001b[0m, in \u001b[0;36mtrain_and_validate_oneEpoch\u001b[1;34m(variables, batches, tbatches, lr)\u001b[0m\n\u001b[0;32m    219\u001b[0m x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    220\u001b[0m y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 221\u001b[0m variables, (loss, logits) \u001b[38;5;241m=\u001b[39m \u001b[43mupdate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;66;03m# jax.debug.print(\"logits: {l}\", l=logits)\u001b[39;00m\n\u001b[0;32m    223\u001b[0m logits \u001b[38;5;241m=\u001b[39m logits\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, logits\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]))\n","    \u001b[1;31m[... skipping hidden 22 frame]\u001b[0m\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v3.py:172\u001b[0m, in \u001b[0;36mupdate_fn\u001b[1;34m(variables, x, y, lr)\u001b[0m\n\u001b[0;32m    169\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jax\u001b[38;5;241m.\u001b[39mvmap, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    170\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jax\u001b[38;5;241m.\u001b[39mpmap, axis_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch\u001b[39m\u001b[38;5;124m'\u001b[39m, in_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), out_axes\u001b[38;5;241m=\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m0\u001b[39m))\n\u001b[0;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fn\u001b[39m(variables, x, y, lr):\n\u001b[1;32m--> 172\u001b[0m     (loss, (logits, variables)), grads \u001b[38;5;241m=\u001b[39m \u001b[43mjax\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalue_and_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhas_aux\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;66;03m# grads = jax.lax.pmean(grads, axis_name='batch')\u001b[39;00m\n\u001b[0;32m    174\u001b[0m     \u001b[38;5;66;03m# jax.debug.print(\"params={v}\", v=jax.tree_map(jnp.shape, variables['params']))\u001b[39;00m\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;66;03m# jax.debug.print(\"lr={v}\", v=jax.tree_map(jnp.shape, lr))\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[38;5;66;03m# jax.debug.print(\"grads mean={v}\", v=grads['params']['ResNetBlock_0']['Conv_0']['kernel'].mean())\u001b[39;00m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;66;03m# jax.debug.print(\"grads var={v}\", v=grads['params']['ResNetBlock_0']['Conv_0']['kernel'].var())\u001b[39;00m\n\u001b[0;32m    180\u001b[0m     variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m param, lr, g: param \u001b[38;5;241m-\u001b[39m lr \u001b[38;5;241m*\u001b[39m g, variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m], lr, grads[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparams\u001b[39m\u001b[38;5;124m'\u001b[39m])\n","    \u001b[1;31m[... skipping hidden 20 frame]\u001b[0m\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v3.py:165\u001b[0m, in \u001b[0;36mloss_fn\u001b[1;34m(variables, x, y, on_train)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;129m@partial\u001b[39m(jax\u001b[38;5;241m.\u001b[39mjit, static_argnums\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mloss_fn\u001b[39m(variables, x, y, on_train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m--> 165\u001b[0m     logits, variables \u001b[38;5;241m=\u001b[39m \u001b[43mnet\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mon_train\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m optax\u001b[38;5;241m.\u001b[39msoftmax_cross_entropy_with_integer_labels(jnp\u001b[38;5;241m.\u001b[39mclip(logits, \u001b[38;5;241m1e-10\u001b[39m, \u001b[38;5;241m1.\u001b[39m), y)\u001b[38;5;241m.\u001b[39mmean(), (logits, variables)\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v3.py:88\u001b[0m, in \u001b[0;36mnet\u001b[1;34m(variables, x, on_train)\u001b[0m\n\u001b[0;32m     85\u001b[0m batch_stats \u001b[38;5;241m=\u001b[39m variables[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbatch_stats\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     87\u001b[0m \u001b[38;5;66;03m# input.T\u001b[39;00m\n\u001b[1;32m---> 88\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mjnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;66;03m# 1st conv\u001b[39;00m\n\u001b[0;32m     91\u001b[0m x \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mlax\u001b[38;5;241m.\u001b[39mconv(x, params[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mConv_0\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkernel\u001b[39m\u001b[38;5;124m'\u001b[39m], window_strides\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), padding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSAME\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","File \u001b[1;32mc:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:543\u001b[0m, in \u001b[0;36mtranspose\u001b[1;34m(a, axes)\u001b[0m\n\u001b[0;32m    541\u001b[0m util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[0;32m    542\u001b[0m axes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(ndim(a))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m axes\n\u001b[1;32m--> 543\u001b[0m axes_ \u001b[38;5;241m=\u001b[39m [_canonicalize_axis(i, ndim(a)) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m axes_]\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mtranspose(a, axes_)\n","File \u001b[1;32mc:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\jax\\_src\\numpy\\lax_numpy.py:543\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    541\u001b[0m util\u001b[38;5;241m.\u001b[39mcheck_arraylike(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtranspose\u001b[39m\u001b[38;5;124m\"\u001b[39m, a)\n\u001b[0;32m    542\u001b[0m axes_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mrange\u001b[39m(ndim(a))[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m axes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m axes\n\u001b[1;32m--> 543\u001b[0m axes_ \u001b[38;5;241m=\u001b[39m [\u001b[43m_canonicalize_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m axes_]\n\u001b[0;32m    544\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m lax\u001b[38;5;241m.\u001b[39mtranspose(a, axes_)\n","File \u001b[1;32mc:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\jax\\_src\\util.py:355\u001b[0m, in \u001b[0;36mcanonicalize_axis\u001b[1;34m(axis, num_dims)\u001b[0m\n\u001b[0;32m    353\u001b[0m axis \u001b[38;5;241m=\u001b[39m operator\u001b[38;5;241m.\u001b[39mindex(axis)\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;241m-\u001b[39mnum_dims \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m<\u001b[39m num_dims:\n\u001b[1;32m--> 355\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maxis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is out of bounds for array of dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_dims\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    356\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m axis \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    357\u001b[0m   axis \u001b[38;5;241m=\u001b[39m axis \u001b[38;5;241m+\u001b[39m num_dims\n","\u001b[1;31mValueError\u001b[0m: axis 3 is out of bounds for array of dimension 3"]}],"source":["# Get the lossmap\n","output_path = f\"./output/{canonical_name()}\"\n","tile_batch = 0\n","zoom_seq = 0\n","loss_deque = deque(maxlen=5)\n","acc_deque = deque(maxlen=5)\n","tloss_deque = deque(maxlen=5)\n","tacc_deque = deque(maxlen=5)\n","minloss_global = 0.\n","\n","send_alram(msg=f\"Start training.\\n{canonical_name()}\")\n","\n","cids = []\n","click_event = [None]\n","trainimg_history = []\n","testimg_history = []\n","img = gen_img(mnmx)\n","\n","plt.close('all')\n","plt.ion()\n","plot_img(img, mnmx, None)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pprint import pprint\n","pprint(loss_deque)\n","pprint(acc_deque)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import jax\n","import jax.numpy as jnp\n","from functools import partial\n","\n","x = jnp.linspace(0, 99, 100).reshape((20, 5))\n","y = jnp.linspace(0, 39, 40).reshape((20, 2))\n","z = jnp.array([[1], [2]])\n","\n","@partial(jax.vmap, in_axes=(None, 0), out_axes=0)\n","def f(x, y):\n","    x += y\n","    return x\n","\n","f(x, z).shape"]},{"cell_type":"markdown","metadata":{"id":"jDC1ScCLooXL"},"source":["# Show all the generated images"]},{"cell_type":"markdown","metadata":{"id":"eIZ9VZzJqIaz"},"source":["## Train images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJLrAXi9YFtg"},"outputs":[],"source":["mfds = estimate_fractal_dimension(trainimg_history, saveas=f'{output_path}/train/mfd.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for ii, impair in enumerate(trainimg_history):\n","    image, mnmx = impair\n","    boundy = extract_edges(image)\n","    fig, ax = plt.subplots(1, 2, figsize=figsize, sharey=True)\n","    ax[0].imshow(boundy)\n","    ax[1].text(0, 0, ps.metrics.boxcount(boundy), verticalalignment='top')\n","    ax[1].axis('off')\n","    plt.savefig(f'{output_path}/train/border_zoom{ii}.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.close('all')\n","\n","for ii, impair in enumerate(trainimg_history):\n","    image, mnmx = impair\n","    newmnmx = None\n","    if ii < len(trainimg_history)-1:\n","        newmnmx = trainimg_history[ii+1][1]\n","    str_ii = f\"{ii:02}\"\n","    letter_dim = \"$median(D_{frac})$\"\n","    \n","    show_img(image, mnmx, newmnmx=newmnmx, handler=False, title=f'{letter_dim}={mfds[ii]:.6f}', savename=f'{output_path}/train/lossmap_zoom{ii}.png')\n","    plt.tight_layout()\n"]},{"cell_type":"markdown","metadata":{"id":"-GKd1BHeqKjX"},"source":["## Test images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqiVg3zEYFth"},"outputs":[],"source":["mfds = estimate_fractal_dimension(testimg_history, saveas=f'{output_path}/test/mfd.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for ii, impair in enumerate(testimg_history):\n","    image, mnmx = impair\n","    boundy = extract_edges(image)\n","    fig, ax = plt.subplots(1, 2, figsize=figsize, sharey=True)\n","    ax[0].imshow(boundy)\n","    ax[1].text(0, 0, ps.metrics.boxcount(boundy), verticalalignment='top')\n","    ax[1].axis('off')\n","    plt.savefig(f'{output_path}/test/border_zoom{ii}.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.close('all')\n","\n","for ii, impair in enumerate(testimg_history):\n","    image, mnmx = impair\n","    newmnmx = None\n","    if ii < len(testimg_history)-1:\n","        newmnmx = testimg_history[ii+1][1]\n","    str_ii = f\"{ii:02}\"\n","    letter_dim = \"$median(D_{frac})$\"\n","    \n","    show_img(image, mnmx, newmnmx=newmnmx, handler=False, title=f'{letter_dim}={mfds[ii]:.6f}', savename=f'{output_path}/test/lossmap_zoom{ii}.png')\n","    plt.tight_layout()\n"]},{"cell_type":"markdown","metadata":{"id":"GrW2rUkvqr_4"},"source":["# Generate a movie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwP2VoByqucJ"},"outputs":[],"source":["train_hist_video = zoom_out_sequence(trainimg_history[-1], growth_factor=2.)\n","test_hist_video = zoom_out_sequence(testimg_history[-1], growth_factor=2.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpZGes88YFth"},"outputs":[],"source":["train_hist_video[0][0][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGuXHVwoq1I4"},"outputs":[],"source":["# each call to increase_resolution increases the resolution of one image and\n","# returns True, or returns False if all images are at or exceed the target resolution\n","while increase_resolution(train_hist_video, test_hist_video, 8):\n","    with open(f'{output_path}/train/{canonical_name(None)}.pickle', 'wb') as handle:\n","        pickle.dump(train_hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    with open(f'{output_path}/test/{canonical_name(None)}.pickle', 'wb') as handle:\n","        pickle.dump(test_hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","ts = 30\n","# train animation\n","anim = make_animator(train_hist_video, timesteps_per_transition=ts*2)\n","anim.save(f'{output_path}/train/{canonical_name(None)}.mp4',fps=ts, dpi=dpi)\n","#test animation\n","anim = make_animator(test_hist_video, timesteps_per_transition=ts*2)\n","anim.save(f'{output_path}/test/{canonical_name(None)}.mp4',fps=ts, dpi=dpi)\n","\n","# officially end\n","plt.close('all')\n","send_alram(\"Finally all over!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4Zzh6g6YFth"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
