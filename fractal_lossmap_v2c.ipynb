{"cells":[{"cell_type":"markdown","metadata":{"id":"InosSXqlwUL4"},"source":["# Loading libraries"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"3-C8YNzAwKQx"},"outputs":[],"source":["# GPU settings\n","import os\n","os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=4'\n","# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,4'\n","\n","\n","# Computation settings\n","import jax\n","from jax import lax, random, config, numpy as jnp\n","# config.update('jax_enable_x64', True)   # for double precision, but cannot run convolution!\n","\n","\n","import porespy as ps\n","import numpy as np\n","\n","# Plotting settings\n","import matplotlib\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.animation as animation\n","from matplotlib import cm\n","\n","# ETC\n","import telegram\n","import pickle\n","import math\n","import datetime\n","from functools import partial\n","from typing import Callable, Any\n","from pprint import pprint\n","\n","from tqdm import tqdm\n","from datetime import datetime\n","from pytz import timezone\n","from collections import deque"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# Model\n","target_dim = 10\n","num_epochs = 30\n","nonlinearity = 'relu'\n","num_blocks = (3, 3, 3)\n","c_hidden = (16, 32, 64)\n","\n","# Datset\n","batch_size = 1024\n","default_outer_batch_size = 32\n","\n","# Plotting\n","default_resolution = 4\n","mnmx = [-4, 0, -4, 0]\n","dpi = 100\n","figsize = (16, 8)\n","interactive_gui = True"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["\n","record_t = datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d_%H%M')[2:]\n","TOKEN = '6740952693:AAFOUwNFVu2O3Bpf7nlKwIlDzyNaarN7Fl8'\n","CHAT_ID = '5110804803'\n","msg = f\"Lossmap was generated!\\nPlease check and zoom it!\"\n","\n","bot = telegram.Bot(TOKEN)\n","\n","def canonical_name(num_blocks=num_blocks, record_t=record_t):\n","    return f\"ResNet-{sum(num_blocks)*2+2}_{record_t}\"\n","\n","def send_alram(msg=msg):\n","    return bot.sendMessage(chat_id=CHAT_ID, text=msg)\n","\n","if interactive_gui:\n","    ## interactive plotting\n","    # from google.colab import output\n","    # output.enable_custom_widget_manager()\n","    %matplotlib ipympl\n","else:\n","    matplotlib.use('Agg')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"S8gcL3ntLx46"},"outputs":[],"source":["# Make the save directory\n","from datetime import datetime\n","from pytz import timezone\n","import json\n","\n","record_t = datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d%H%M%S')[2:]\n","output_path = f\"./output/{canonical_name()}\"\n","os.makedirs(output_path + \"/train\", exist_ok=True)\n","os.makedirs(output_path + \"/test\", exist_ok=True)\n","\n","# metadata\n","metadata = {\n","    'model_hyperparams': {\n","        'layers': sum(num_blocks)*2+2,\n","        'num_blocks': num_blocks,\n","        'c_hidden': c_hidden,\n","        'num_epochs': num_epochs,\n","        'batch_size': batch_size,\n","        'activation': nonlinearity,\n","    },\n","    'plot_hyperparams': {\n","        'resolution': default_resolution,\n","        'initial_bound': mnmx,\n","    },\n","    'recording(UTC+9)': record_t\n","}\n","\n","with open(f'{output_path}/metadata.json', 'w') as md:\n","    json.dump(metadata, md, indent=4)"]},{"cell_type":"markdown","metadata":{"id":"36XJLykLBgzk"},"source":["# Modeling"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["from datasets.mnist import *\n","\n","train_ds = data_normalize(train_ds).shuffle(buffer_size=10, seed=42).batch(batch_size).prefetch(1)\n","test_ds = data_normalize(test_ds).shuffle(buffer_size=10, seed=42).batch(batch_size).prefetch(1)\n","\n","total_batch = train_ds.cardinality().numpy()\n","total_tbatch = test_ds.cardinality().numpy()\n","\n","for batch in train_ds.as_numpy_iterator():\n","    x = batch['image']\n","    y = batch['label']\n","    break\n"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["from model.resnet_v2b import *\n","\n","resnet = ResNet(num_classes=target_dim, act_fn=nn.relu, block_class=ResNetBlock, num_blocks=num_blocks, c_hidden=c_hidden)\n","# variables = initialize(resnet, 42, x)\n","# variables = jax.tree_map(lambda x: jnp.tile(x, (default_resolution,)+(1,)*len(x.shape)), variables)"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# from model.shallownet import *\n","from plot.trendline import plot_trend\n","from collections import deque\n","\n","def split_and_train(resnet, hparams, batches, tbatches, num_epochs):\n","    global tile_batch, zoom_seq\n","    global loss_deque, tloss_deque, acc_deque, tacc_deque, minloss_global\n","\n","    # Cut off the learning rates as bite size\n","    bs = hparams.shape[0]\n","    if bs > default_outer_batch_size:\n","        train_loss1, test_loss1 = split_and_train(resnet, hparams[:bs//2, ], batches, tbatches, num_epochs)\n","        train_loss2, test_loss2 = split_and_train(resnet, hparams[bs//2:, ], batches, tbatches, num_epochs)\n","        return jnp.concatenate((train_loss1, train_loss2), axis=0), jnp.concatenate((test_loss1, test_loss2), axis=0)\n","\n","    # variables, copied\n","    variables = initialize(resnet, 42, x)\n","    variables = jax.tree_map(lambda x: jnp.tile(x, (bs,)+(1,)*len(x.shape)), variables)\n","\n","    ### tree_map\n","    # apply each other offset and learning rate\n","    tile_batch += 1\n","    desc = f'[Tile {tile_batch}/{math.ceil(default_resolution**2/default_outer_batch_size)}] Training-epochs: '\n","    loss_archive, acc_archive, tloss_archive, tacc_archive = train_on_the_track(variables, batches, tbatches, hparams, num_epochs, desc=desc)\n","\n","    # TOP5 ranking\n","    def min_tournament(loss_archive):\n","        loss_arr = np.array(loss_archive).T\n","        minloss = loss_arr[:, -20:].mean(axis=1)\n","        px_minloss = minloss.argmin()\n","        minloss = minloss.min()\n","        return px_minloss, minloss\n","\n","    # Find the well-converged train loss and get them up!\n","    px_minloss, minloss = min_tournament(loss_archive)\n","    loss_arr = np.array(loss_archive).T\n","    acc_arr = np.array(acc_archive).T\n","    tloss_arr = np.array(tloss_archive).T\n","    tacc_arr = np.array(tacc_archive).T\n","\n","    if minloss_global > minloss:\n","        minloss_global = minloss\n","        px = (tile_batch - 1) * default_outer_batch_size + px_minloss\n","        loss_deque.appendleft({f\"{px}\": loss_arr[px_minloss]})\n","        acc_deque.appendleft({f\"{px}\": acc_arr[px_minloss]})\n","        tloss_deque.appendleft({f\"{px}\": tloss_arr[px_minloss]})\n","        tacc_deque.appendleft({f\"{px}\": tacc_arr[px_minloss]})\n","    \n","\n","    return convergence_measure(jnp.stack(loss_archive, axis=-1)), convergence_measure(jnp.stack(tloss_archive, axis=-1))    # stack-->(16, 100), convergence_measure-->(...?)\n","\n","\n","# Compensator\n","@partial(jax.vmap, in_axes=(0,), out_axes=0)\n","def convergence_measure(v, max_val=1e6):\n","    fin = jnp.isfinite(v)\n","    v = v * fin + max_val * (1-fin)\n","    v /= v[0]\n","    exceeds = (v > max_val)\n","    v = v * (1-exceeds) + max_val * exceeds\n","    # converged = (jnp.mean(v[-20:]) < 1)\n","    \n","    return -(1-jnp.mean(v))\n"]},{"cell_type":"markdown","metadata":{"id":"szLdaCvzhItA"},"source":["# Plotting and Measure the Fractal Dimension"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"GxkGz1-whK3-"},"outputs":[],"source":["from sklearn.linear_model import LinearRegression\n","\n","# Generate the lossmap\n","def gen_img(mnmx, resolution=None):\n","    \"\"\"\n","    generate an image of the hyperparameter landscape,\n","    for a range of hyperparameter values specified by mnmx\n","    \"\"\"\n","    global zoom_seq, loss_deque, tloss_deque, acc_deque, tacc_deque, minloss_global\n","\n","    loss_deque = deque(maxlen=5)\n","    tloss_deque = deque(maxlen=5)\n","    acc_deque = deque(maxlen=5)\n","    tacc_deque = deque(maxlen=5)\n","\n","    minloss_global = np.float32('inf')\n","\n","    if resolution is None:\n","        resolution = default_resolution\n","\n","    mn1, mx1, mn2, mx2 = mnmx\n","    gg1 = jnp.logspace(mn1, mx1, resolution)\n","    gg2 = jnp.logspace(mn2, mx2, resolution)\n","    lr0, lr1 = jnp.meshgrid(gg2, gg1)\n","    lr = jnp.stack([lr0.ravel(), lr1.ravel()], axis=-1)\n","\n","    V, tV = split_and_train(\n","        resnet=resnet,\n","        hparams=lr,\n","        batches=train_ds,\n","        tbatches=test_ds,\n","        num_epochs=num_epochs\n","        )\n","    \n","    # plot the loss trend\n","    plot_trend(loss_deque, ylabel='Loss', saveas=f'{output_path}/train/convTOP5_loss_zoom{zoom_seq}.png')\n","    plot_trend(acc_deque, ylabel='Acc', saveas=f'{output_path}/train/convTOP5_acc_zoom{zoom_seq}.png')\n","    plot_trend(tloss_deque, ylabel='Loss', saveas=f'{output_path}/test/convTOP5_vloss_zoom{zoom_seq}.png')\n","    plot_trend(tacc_deque, ylabel='Acc', saveas=f'{output_path}/test/convTOP5_vacc_zoom{zoom_seq}.png')\n","\n","    V = V.reshape((resolution, resolution))\n","    tV = tV.reshape((resolution, resolution))\n","\n","    send_alram(msg=msg)\n","\n","\n","    return V, tV\n","\n","\n","# Measure the fractal dim\n","def extract_edges(X):\n","    \"\"\"\n","    define edges as sign changes in the scalar representing convergence or\n","    divergence rate -- on one side of the edge training converges,\n","    while on the other side of the edge training diverges\n","    \"\"\"\n","\n","    Y = jnp.stack((X[1:,1:], X[:-1,1:], X[1:,:-1], X[:-1,:-1]), axis=-1)\n","    Z = jnp.sign(jnp.max(Y, axis=-1)*jnp.min(Y, axis=-1))\n","    return Z<0\n","\n","def estimate_fractal_dimension(hist_video, show_plot=True, saveas=None, bins=30):\n","    if show_plot:\n","        fig, ax = plt.subplots(1, 2, figsize=(4, 4), constrained_layout=True)\n","        ax.set_yscale('log')\n","        ax.set_xscale('log')\n","        ax.set_xlabel('box edge length')\n","        ax.set_ylabel('number of boxes spanning phases')\n","        # ax2.set_xlabel('box edge length')\n","        # ax2.set_ylabel('slope')\n","        # ax2.set_xscale('log')\n","\n","    mfds = []\n","    for n, U in enumerate(hist_video):\n","        edge = extract_edges(U[0])\n","        bc = ps.metrics.boxcount(edge, bins=bins)\n","        mfd = np.median(bc.slope)\n","        mfds.append(mfd)\n","        print(f'Median fractal dimension: {mfd} at zoom{n}')\n","\n","        bc_x = np.log10(bc.size).reshape((-1, 1))\n","        bc_y = np.log10(bc.count)\n","        bc_linear = LinearRegression().fit(bc_x, bc_y)\n","        \n","        bc_newx = np.log10(np.linspace(bc.size.min(), bc.size.max(), 2)).reshape((-1, 1))\n","        bc_newy = 10**(bc_linear.predict(bc_newx))\n","\n","        if show_plot:\n","            # ax1.plot(bc.size, bc.count, '-o', alpha=0.7, label=f'Zoom{n}, mfd={mfd:.3f}')\n","            # ax2.plot(bc.size, bc.slope, '-o', alpha=0.7, label=f'Zoom{n}, mfd={mfd:.3f}')\n","            ax.scatter(bc.size, bc.count, s=10, label=f'Zoom{n}, mfd={mfd:.3f}')\n","            ax.plot(10**bc_newx, bc_newy, '-', linewidth=1)\n","            # ax2.scatter(bc.size, bc.slope, s=10, label=f'Zoom{n}, mfd={mfd:.3f}')\n","    \n","    if saveas:\n","        plt.legend()\n","        plt.savefig(saveas)\n","\n","    return mfds\n","\n","# Interploating\n","def cdf_img(x, x_ref, buffer=0.25):\n","    \"\"\"\n","    rescale x, relative to x_ref (x_ref is often the same as x), to achieve a uniform\n","    distribution over values with positive and negative intensities, but also to\n","    preserve the sign of x. This makes for a visualization that shows more\n","    structure.\n","    \"\"\"\n","    u = jnp.sort(x_ref.ravel())\n","    num_neg = jnp.sum(u<0)\n","    num_nonneg = u.shape[0] - num_neg\n","    v = jnp.concatenate((jnp.linspace(-1,-buffer,num_neg), jnp.linspace(buffer,1,num_nonneg)), axis=0)\n","    y = jnp.interp(x, u, v)\n","    return -y\n","\n","\n","# Notation\n","def truncate_sci_notation(numbers):\n","    \"\"\"\n","    keeping enough significant digits that the\n","    numbers disagree in four digits\n","    \"\"\"\n","\n","    # Convert numbers to scientific notation\n","    n1_sci, n2_sci = \"{:.15e}\".format(numbers[0]), \"{:.15e}\".format(numbers[1])\n","\n","    # Extract the significant parts and exponents\n","    sig_n1, exp_n1 = n1_sci.split('e')\n","    sig_n2, exp_n2 = n2_sci.split('e')\n","\n","    # Find the first position at which they disagree\n","    min_len = min(len(sig_n1), len(sig_n2))\n","    truncate_index = min_len\n","\n","    for i in range(min_len):\n","        if (sig_n1[i] != sig_n2[i]) or (exp_n1 != exp_n2):\n","            # +4 accounts for 4 digits after the first disagreement\n","            truncate_index = i + 4\n","            if i == 0:\n","                truncate_index += 1 # Account for decimal point\n","        break\n","\n","    exp_n1 = exp_n1[0] + exp_n1[2]\n","    exp_n2 = exp_n2[0] + exp_n2[2]\n","    if (exp_n1 == \"+00\") and (exp_n2 == \"+00\"):\n","        # don't bother with scientific notation if exponent is 0\n","        return [sig_n1[:truncate_index], sig_n2[:truncate_index]]\n","\n","    # Truncate and reconstruct the scientific notation\n","    truncated_n1 = \"{}e{}\".format(sig_n1[:truncate_index], exp_n1)\n","    truncated_n2 = \"{}e{}\".format(sig_n2[:truncate_index], exp_n2)\n","\n","    return [truncated_n1, truncated_n2]\n","\n","def tickslabels(mnmx):\n","    return mnmx, truncate_sci_notation(10.**np.array(mnmx))"]},{"cell_type":"code","execution_count":20,"metadata":{"id":"MrJfi2LYjceH"},"outputs":[],"source":["# Animating zoom sequences and interpolating between frames\n","def zoom_out_sequence(hist_final, growth_factor=2., max_scale=6):\n","  \"\"\"\n","  generate a sequence of (image, bounds) zooming out from the (image, bounds) in hist_final\n","  \"\"\"\n","\n","  image, mnmx = hist_final\n","\n","  cT = np.array([(mnmx[0] + mnmx[1])/2., (mnmx[2] + mnmx[3])/2.])\n","  wT = np.array([mnmx[1] - mnmx[0], mnmx[3] - mnmx[2]])\n","\n","  hist = [(image, mnmx)]\n","  w_scale = 1.\n","  while np.min(wT * w_scale) < max_scale:\n","    w_scale *= 2\n","    mnmx = [\n","        cT[0] - w_scale * wT[0]/2.,\n","        cT[0] + w_scale * wT[0]/2.,\n","        cT[1] - w_scale * wT[1]/2.,\n","        cT[1] + w_scale * wT[1]/2.,\n","    ]\n","    hist.insert(0, (np.zeros((2,2)), mnmx))\n","\n","  return hist\n","\n","def increase_resolution(history, target_res):\n","  \"\"\"\n","  Increase the resolution of images of a fractal landscape that we've already\n","  generated.\n","\n","  Find the first entry in history with resolution below target_res, and increase\n","  its resolution. If all images are already at least the target resolution,\n","  return False.\n","  \"\"\"\n","\n","  new_h = []\n","  for ii in range(len(history)):\n","    h = history[ii]\n","    image, mnmx = h\n","    if image.shape[0] < target_res:\n","      current_time = datetime.datetime.now()\n","      print( f\"increasing resolution of {ii} / {len(history)} at {current_time}, current resolution is {image.shape}\")\n","      image = gen_img(mnmx, resolution=target_res)\n","      history[ii] = (image, mnmx)\n","      return True\n","  return False\n","\n","def interpolate_history(hist1, hist2, alpha):\n","  \"\"\"\n","  get the mnmx (hyperparameter bounding box) value for a fraction alpha between\n","  two images\n","  \"\"\"\n","\n","  _, mnmx1 = hist1\n","  _, mnmx2 = hist2\n","\n","  if alpha == 0:\n","    # avoid NaNs on very last frame\n","    return mnmx1\n","\n","  w1 = np.array([mnmx1[1] - mnmx1[0], mnmx1[3] - mnmx1[2]])\n","  w2 = np.array([mnmx2[1] - mnmx2[0], mnmx2[3] - mnmx2[2]])\n","  c1 = np.array([(mnmx1[0] + mnmx1[1])/2, (mnmx1[2] + mnmx1[3])/2])\n","  c2 = np.array([(mnmx2[0] + mnmx2[1])/2, (mnmx2[2] + mnmx2[3])/2])\n","\n","  gamma = np.exp((1-alpha)*0 + alpha*np.log(w2/w1))\n","\n","  # ct = cstar + (c1 - cstar)*gamma\n","  # c1 = cstar + (c1 - cstar)*1\n","  # c2 = cstar + (c1 - cstar)*w2/w1\n","  cstar = (c2 - c1*w2/w1) / (1 - w2 / w1)\n","\n","  ct = cstar + (c1 - cstar)*gamma\n","  hwt = gamma*w1\n","\n","  return [ct[0] - hwt[0]/2, ct[0] + hwt[0]/2, ct[1] - hwt[1]/2, ct[1] + hwt[1]/2]\n","\n","\n","def em(extent_rev):\n","  return [extent_rev[2], extent_rev[3], extent_rev[0], extent_rev[1]]\n","\n","def make_animator(history, timesteps_per_transition=60, reference_scale=None, cmap='Spectral'):\n","\n","  fig, ax, im1 = show_img(history[0][0], history[0][1], newmnmx=None,\n","                          handler=False, reference_scale=reference_scale, cmap=cmap)\n","\n","  im2 = ax.imshow(\n","      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n","      vmin = -1, vmax = 1,\n","      cmap=cmap,\n","      aspect='auto',\n","      interpolation='nearest'\n","      )\n","\n","  im3 = ax.imshow(\n","      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n","      vmin = -1, vmax = 1,\n","      cmap=cmap,\n","      aspect='auto',\n","      interpolation='nearest'\n","      )\n","\n","  def animate(n):\n","    hist_index = n // timesteps_per_transition\n","    alpha = (n % timesteps_per_transition) / timesteps_per_transition\n","\n","    hist1 = history[hist_index]\n","    if hist_index >= len(history)-1:\n","      hist2 = hist1 # very last frame\n","    else:\n","      hist2 = history[hist_index+1]\n","    if hist_index >= len(history)-2:\n","      hist3 = hist2 # very last frame\n","    else:\n","      hist3 = history[hist_index+2]\n","\n","    lims = interpolate_history(hist1, hist2, alpha)\n","\n","    # interpolation scheme for image restretch / colormap\n","    alpha_area = jnp.sin(alpha*np.pi/2)**2\n","\n","    print(f'frame {n} / {timesteps_per_transition*len(history)}, zoom step {hist_index} / {len(history)}', end='\\r', flush=True)\n","\n","    img_1 = (1-alpha_area)*cdf_img(hist1[0], hist1[0]) + alpha_area*cdf_img(hist1[0], hist2[0])\n","    img_2 = (1-alpha_area)*cdf_img(hist2[0], hist1[0]) + alpha_area*cdf_img(hist2[0], hist2[0])\n","    img_3 = (1-alpha_area)*cdf_img(hist3[0], hist1[0]) + alpha_area*cdf_img(hist3[0], hist2[0])\n","\n","    im1.set_data(img_1)\n","    im1.set_extent(em(hist1[1]))\n","    im2.set_data(img_2)\n","    im2.set_extent(em(hist2[1]))\n","    im3.set_data(img_3)\n","    im3.set_extent(em(hist3[1]))\n","    im3.set_alpha(alpha)\n","\n","    ax.set_ylim(lims[0], lims[1])\n","    ax.set_xlim(lims[2], lims[3])\n","\n","    # Set the new tick positions\n","    ax.set_xticks(*tickslabels([lims[2], lims[3]]))\n","    ax.set_yticks(*tickslabels([lims[0], lims[1]]), rotation=90)\n","\n","    labels = ax.get_xticklabels()\n","    labels[0].set_horizontalalignment('left')\n","    labels[1].set_horizontalalignment('right')\n","    labels = ax.get_yticklabels()\n","    labels[0].set_verticalalignment('bottom')\n","    labels[1].set_verticalalignment('top')\n","\n","    return fig,\n","\n","  anim = animation.FuncAnimation(fig,animate,frames=timesteps_per_transition*(len(history)-1)+1, repeat=False)\n","  return anim"]},{"cell_type":"code","execution_count":21,"metadata":{"id":"4rKdJxPsUfnF"},"outputs":[],"source":["# Interactive plotting\n","cids = []\n","click_event = [None]\n","\n","def onclick(event):\n","    click_event[0] = (event.xdata, event.ydata)\n","\n","def onrelease(event, fig, im, rect, mnmx, img, recalculate_image=True):\n","    global tile_batch, zoom_seq\n","    tile_batch = 0\n","    zoom_seq += 1\n","    \n","    if click_event[0] is None:\n","        return\n","\n","    e0 = [click_event[0][0], event.xdata]\n","    e1 = [click_event[0][1], event.ydata]\n","\n","    for v in e0+e1:\n","        if v is None:\n","            return\n","\n","    newmnmx = [np.min(e1), np.max(e1), np.min(e0), np.max(e0)]\n","\n","    min_w = (mnmx[1] - mnmx[0])/20\n","    if newmnmx[1] - newmnmx[0] < min_w:\n","        c = (newmnmx[1] + newmnmx[0])/2.\n","        newmnmx[0] = c - min_w/2\n","        newmnmx[1] = c + min_w/2\n","    min_w = (mnmx[3] - mnmx[2])/20\n","\n","    if newmnmx[1] - newmnmx[0] < min_w:\n","        c = (newmnmx[3] + newmnmx[2])/2.\n","        newmnmx[2] = c - min_w/2\n","        newmnmx[3] = c + min_w/2\n","\n","    for v in newmnmx:\n","        if v is None:\n","            return\n","\n","    plot_img(img, mnmx, newmnmx, fig=fig, im=im, rect=rect)\n","    plt.draw()\n","\n","    if recalculate_image:\n","        click_event[0] = None\n","        mnmx = newmnmx\n","        img = gen_img(mnmx)\n","        plot_img(img, mnmx, None, fig=fig, im=im, rect=rect)\n","\n","\n","def plot_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n","             handler=True, savename=None,\n","             reference_scale=None,\n","             cmap='Spectral',\n","             title=\"\"\n","             ):\n","\n","    global loss_deque, acc_deque, tloss_deque, tacc_deque, default_outer_batch_size\n","\n","    mn1, mx1, mn2, mx2 = mnmx\n","    trainimg, testimg = image\n","\n","    if reference_scale is None:\n","        reference_scale_train = trainimg\n","        reference_scale_test = testimg\n","\n","\n","    trainimg = cdf_img(trainimg, reference_scale_train)\n","    testimg = cdf_img(testimg, reference_scale_test)\n","\n","    # ax1 = None\n","    if im is not None:\n","        im1, im2 = im\n","\n","    if fig is None:\n","        # fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi, sharey=True, constrained_layout=True)\n","        fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi, sharey=True)\n","\n","        ax = ax.flatten()\n","        im1 = ax[0].imshow(trainimg,\n","                        extent=[mn2, mx2, mn1, mx1],\n","                        origin='lower',\n","                        vmin=-1, vmax=1,\n","                        cmap=cmap,\n","                        aspect='auto',\n","                        interpolation='nearest'\n","                        )\n","        im2 = ax[1].imshow(testimg,\n","                        extent=[mn2, mx2, mn1, mx1],\n","                        origin='lower',\n","                        vmin=-1, vmax=1,\n","                        cmap=cmap,\n","                        aspect='auto',\n","                        interpolation='nearest'\n","                        )\n","        # fig.colorbar(im1, ax=ax.ravel().tolist())\n","        if title == \"\":\n","            batch_text = f\"{num_epochs} epochs, {batch_size} batches\"\n","            title = f'Trainability dependence on parameter initialization and learning rates'\n","        fig.suptitle(title)\n","\n","        fig.supxlabel('Input layer weight offset')\n","        fig.supylabel('Learning rate')\n","\n","        rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","        ax[0].add_patch(rect)\n","        rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","        ax[1].add_patch(rect)\n","\n","    im1.set_extent([mn2, mx2, mn1, mx1])\n","    im1.set_data(trainimg)\n","    im2.set_extent([mn2, mx2, mn1, mx1])\n","    im2.set_data(testimg)\n","\n","    # Set the new tick positions on the x-axis\n","    # aaxx = plt.gca()\n","    ax = fig.axes\n","    ax[0].set_title(\"Training Lossmap\")\n","    ax[1].set_title(\"Evaluating Lossmap\")\n","\n","    for nn, aaxx in enumerate(ax):\n","        aaxx.set_xticks(*tickslabels([mn2, mx2]))\n","        aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n","\n","        labels = aaxx.get_xticklabels()\n","        labels[0].set_horizontalalignment('left')\n","        labels[1].set_horizontalalignment('right')\n","        if nn == 0:\n","            labels = aaxx.get_yticklabels()\n","            labels[0].set_verticalalignment('bottom')\n","            labels[1].set_verticalalignment('top')\n","\n","    if handler and (newmnmx is None):\n","        trainimg_history.append((trainimg, mnmx))\n","        testimg_history.append((testimg, mnmx))\n","\n","\n","    if newmnmx:\n","        mn1, mx1, mn2, mx2 = newmnmx\n","    rect.set_xy((mn2, mn1))\n","    rect.set_width(mx2-mn2)\n","    rect.set_height(mx1-mn1)\n","\n","    if handler:\n","        while len(cids) > 0:\n","            fig.canvas.mpl_disconnect(cids.pop())\n","\n","    def onrelease_partial(event):\n","        return onrelease(event, fig, im, rect, mnmx, img)\n","    def onmotion_partial(event):\n","        return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n","\n","    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n","    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n","    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n","\n","    # plt.tight_layout()\n","\n","    im = (im1, im2)\n","    plt.draw()\n","\n","    if savename:\n","        plt.savefig(savename)\n","\n","    # Star-patch\n","    for rank, px in enumerate(loss_deque):\n","        patch_coord = [(int(k) % default_resolution, int(k) // default_resolution) for k, _ in px.items()][0]\n","        ax[0].text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax[0].transAxes)\n","        ax[1].text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax[1].transAxes)\n","\n","\n","    return fig, ax, im\n","\n","\n","def increase_resolution(train_history, test_history, target_res):\n","  \"\"\"\n","  Increase the resolution of images of a fractal landscape that we've already\n","  generated.\n","\n","  Find the first entry in history with resolution below target_res, and increase\n","  its resolution. If all images are already at least the target resolution,\n","  return False.\n","  \"\"\"\n","\n","  new_h = []\n","  for ii in range(len(train_history)):\n","    train_h = train_history[ii]\n","    test_h = test_history[ii]\n","\n","    train_image, train_mnmx = train_h\n","    test_image, test_mnmx = test_h\n","\n","    if train_image.shape[0] < target_res:\n","      current_time = datetime.now()\n","      print( f\"increasing resolution of {ii} / {len(train_history)} at {current_time}, current resolution is {train_image.shape}\")\n","      train_image, test_image = gen_img(train_mnmx, resolution=target_res)\n","      train_history[ii] = (train_image, train_mnmx)\n","      test_history[ii] = (test_image, test_mnmx)\n","\n","      return True\n","  return False\n"]},{"cell_type":"code","execution_count":22,"metadata":{"id":"RLsWZXMIpeQZ"},"outputs":[],"source":["def show_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n","             handler=True, savename=None,\n","             reference_scale=None,\n","             cmap='Spectral_r',\n","             title=\"\"\n","             ):\n","  \n","  global loss_deque, acc_deque, tloss_deque, tacc_deque, default_outer_batch_size\n","  \n","  mn1, mx1, mn2, mx2 = mnmx\n","\n","  if reference_scale is None:\n","    reference_scale = image\n","\n","  image = cdf_img(image, reference_scale)\n","\n","  ax1 = None\n","  if fig is None:\n","    fig, (ax1) = plt.subplots(figsize=(figsize[0]/2, figsize[1]), dpi=dpi)\n","    im = ax1.imshow(image,\n","                    extent=[mn2, mx2, mn1, mx1],\n","                    origin='lower',\n","                    vmin=-1, vmax=1,\n","                    cmap=cmap,\n","                    aspect='auto',\n","                    interpolation='nearest'\n","                    )\n","    fig.colorbar(im, ax=ax1)\n","\n","    if title == \"\":\n","      batch_text = f\"{num_epochs} epochs, {batch_size} batches\"\n","      title = 'Trainability dependence on parameter initialization and learning rates'\n","    fig.suptitle(title)\n","   \n","    ax1.set_ylabel('Learning rate')\n","    ax1.set_xlabel('Input layer weight offset')\n","\n","    rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","    ax1.add_patch(rect)\n","\n","  im.set_extent([mn2, mx2, mn1, mx1])\n","  im.set_data(image)\n","\n","  # Set the new tick positions on the x-axis\n","  aaxx = plt.gca()\n","  aaxx.set_xticks(*tickslabels([mn2, mx2]))\n","  aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n","\n","  labels = aaxx.get_xticklabels()\n","  labels[0].set_horizontalalignment('left')\n","  labels[1].set_horizontalalignment('right')\n","  labels = aaxx.get_yticklabels()\n","  labels[0].set_verticalalignment('bottom')\n","  labels[1].set_verticalalignment('top')\n","\n","  if handler and (newmnmx is None):\n","    image_history.append((image, mnmx))\n","\n","  if newmnmx:\n","    mn1, mx1, mn2, mx2 = newmnmx\n","  rect.set_xy((mn2, mn1))\n","  rect.set_width(mx2-mn2)\n","  rect.set_height(mx1-mn1)\n","\n","  if handler:\n","    while len(cids) > 0:\n","      fig.canvas.mpl_disconnect(cids.pop())\n","\n","    def onrelease_partial(event):\n","      return onrelease(event, fig, im, rect, mnmx, img)\n","    def onmotion_partial(event):\n","      return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n","\n","    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n","    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n","    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n","\n","  # plt.tight_layout()\n","  plt.draw()\n","\n","  if savename:\n","    plt.savefig(savename)\n","  \n","  for rank, px in enumerate(loss_deque):\n","    patch_coord = [(int(k) % default_resolution, int(k) // default_resolution) for k, _ in px.items()][0]\n","    ax1.text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax1.transAxes)\n","  savename_marked = savename.split('.')\n","  savename_marked[1] = savename_marked[1] + \"_starred\"\n","  savename_marked = \".\".join(savename_marked)\n","  plt.savefig(savename_marked)\n","  \n","\n","  return fig, ax1, im"]},{"cell_type":"markdown","metadata":{"id":"esuAL5tAit2N"},"source":["# Generating the lossmap"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":94382,"status":"error","timestamp":1711987939194,"user":{"displayName":"J U","userId":"09528049220557542940"},"user_tz":-540},"id":"H3r5KDHEhEeu","outputId":"5eb04283-2918-49e5-88ad-e9f48c8c0345"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\konyang\\AppData\\Local\\Temp\\ipykernel_31576\\1772814733.py:11: RuntimeWarning: coroutine 'Bot.send_message' was never awaited\n","  send_alram(msg=f\"Start training.\\n{canonical_name()}\")\n","RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n","                                                                  \r"]},{"ename":"XlaRuntimeError","evalue":"RESOURCE_EXHAUSTED: Out of memory allocating 23429709952 bytes.: while running replica 1 and partition 0 of a replicated computation (other replicas may have failed as well).","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mXlaRuntimeError\u001b[0m                           Traceback (most recent call last)","Cell \u001b[1;32mIn[23], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m trainimg_history \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m     16\u001b[0m testimg_history \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m---> 17\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mgen_img\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmnmx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m plt\u001b[38;5;241m.\u001b[39mclose(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mion()\n","Cell \u001b[1;32mIn[19], line 27\u001b[0m, in \u001b[0;36mgen_img\u001b[1;34m(mnmx, resolution)\u001b[0m\n\u001b[0;32m     24\u001b[0m lr0, lr1 \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mmeshgrid(gg2, gg1)\n\u001b[0;32m     25\u001b[0m lr \u001b[38;5;241m=\u001b[39m jnp\u001b[38;5;241m.\u001b[39mstack([lr0\u001b[38;5;241m.\u001b[39mravel(), lr1\u001b[38;5;241m.\u001b[39mravel()], axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 27\u001b[0m V, tV \u001b[38;5;241m=\u001b[39m \u001b[43msplit_and_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresnet\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresnet\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     30\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtbatches\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_ds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\n\u001b[0;32m     33\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# plot the loss trend\u001b[39;00m\n\u001b[0;32m     36\u001b[0m plot_trend(loss_deque, ylabel\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoss\u001b[39m\u001b[38;5;124m'\u001b[39m, saveas\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/train/convTOP5_loss_zoom\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mzoom_seq\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[1;32mIn[18], line 24\u001b[0m, in \u001b[0;36msplit_and_train\u001b[1;34m(resnet, hparams, batches, tbatches, num_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m tile_batch \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     23\u001b[0m desc \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[Tile \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtile_batch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmath\u001b[38;5;241m.\u001b[39mceil(default_resolution\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m/\u001b[39mdefault_outer_batch_size)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Training-epochs: \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 24\u001b[0m loss_archive, acc_archive, tloss_archive, tacc_archive \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_the_track\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdesc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdesc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# TOP5 ranking\u001b[39;00m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmin_tournament\u001b[39m(loss_archive):\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v2b.py:189\u001b[0m, in \u001b[0;36mtrain_on_the_track\u001b[1;34m(variables, batches, tbatches, hparams, epochs, desc)\u001b[0m\n\u001b[0;32m    186\u001b[0m lr \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mtree_map(\u001b[38;5;28;01mlambda\u001b[39;00m lr: lr\u001b[38;5;241m.\u001b[39mreshape(((\u001b[38;5;241m4\u001b[39m, lr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m4\u001b[39m) \u001b[38;5;241m+\u001b[39m lr\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m:])), lr)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(epochs), total\u001b[38;5;241m=\u001b[39mepochs, desc\u001b[38;5;241m=\u001b[39mdesc, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 189\u001b[0m     variables, loss, acc, tloss, tacc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate_oneEpoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtbatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    191\u001b[0m     \u001b[38;5;66;03m# print(f\"Epoch{_} loss={loss.shape} acc={acc.shape}\")\u001b[39;00m\n\u001b[0;32m    192\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mreshape((loss\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m*\u001b[39m loss\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]))\n","File \u001b[1;32md:\\Workspace\\[인공지능연구팀]fractal\\1\\fractal_v3\\model\\resnet_v2b.py:234\u001b[0m, in \u001b[0;36mtrain_and_validate_oneEpoch\u001b[1;34m(variables, batches, tbatches, lr)\u001b[0m\n\u001b[0;32m    232\u001b[0m     x \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    233\u001b[0m     y \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 234\u001b[0m     variables, loss, acc, grads \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvariables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tbatch \u001b[38;5;129;01min\u001b[39;00m tbatches\u001b[38;5;241m.\u001b[39mas_numpy_iterator():\n\u001b[0;32m    237\u001b[0m     tx \u001b[38;5;241m=\u001b[39m tbatch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage\u001b[39m\u001b[38;5;124m'\u001b[39m]\n","    \u001b[1;31m[... skipping hidden 3 frame]\u001b[0m\n","File \u001b[1;32mc:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\jax\\_src\\interpreters\\pxla.py:1209\u001b[0m, in \u001b[0;36mExecuteReplicated.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1207\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_token_bufs(result_token_bufs, sharded_runtime_token)\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1209\u001b[0m   results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mxla_executable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute_sharded\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_bufs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dispatch\u001b[38;5;241m.\u001b[39mneeds_check_special():\n\u001b[0;32m   1211\u001b[0m   out_arrays \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mdisassemble_into_single_device_arrays()\n","\u001b[1;31mXlaRuntimeError\u001b[0m: RESOURCE_EXHAUSTED: Out of memory allocating 23429709952 bytes.: while running replica 1 and partition 0 of a replicated computation (other replicas may have failed as well)."]}],"source":["# Get the lossmap\n","output_path = f\"./output/{canonical_name()}\"\n","tile_batch = 0\n","zoom_seq = 0\n","loss_deque = deque(maxlen=5)\n","acc_deque = deque(maxlen=5)\n","tloss_deque = deque(maxlen=5)\n","tacc_deque = deque(maxlen=5)\n","minloss_global = 0.\n","\n","send_alram(msg=f\"Start training.\\n{canonical_name()}\")\n","\n","cids = []\n","click_event = [None]\n","trainimg_history = []\n","testimg_history = []\n","img = gen_img(mnmx)\n","\n","plt.close('all')\n","plt.ion()\n","plot_img(img, mnmx, None)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pprint import pprint\n","pprint(loss_deque)\n","pprint(acc_deque)"]},{"cell_type":"markdown","metadata":{"id":"jDC1ScCLooXL"},"source":["# Show all the generated images"]},{"cell_type":"markdown","metadata":{"id":"eIZ9VZzJqIaz"},"source":["## Train images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJLrAXi9YFtg"},"outputs":[],"source":["mfds = estimate_fractal_dimension(trainimg_history, saveas=f'{output_path}/train/mfd.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for ii, impair in enumerate(trainimg_history):\n","    image, mnmx = impair\n","    boundy = extract_edges(image)\n","    fig, ax = plt.subplots(1, 2, figsize=figsize, sharey=True)\n","    ax[0].imshow(boundy)\n","    ax[1].text(0, 0, ps.metrics.boxcount(boundy), verticalalignment='top')\n","    ax[1].axis('off')\n","    plt.savefig(f'{output_path}/train/border_zoom{ii}.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.close('all')\n","\n","for ii, impair in enumerate(trainimg_history):\n","    image, mnmx = impair\n","    newmnmx = None\n","    if ii < len(trainimg_history)-1:\n","        newmnmx = trainimg_history[ii+1][1]\n","    str_ii = f\"{ii:02}\"\n","    letter_dim = \"$median(D_{frac})$\"\n","    \n","    show_img(image, mnmx, newmnmx=newmnmx, handler=False, title=f'{letter_dim}={mfds[ii]:.6f}', savename=f'{output_path}/train/lossmap_zoom{ii}.png')\n","    plt.tight_layout()\n"]},{"cell_type":"markdown","metadata":{"id":"-GKd1BHeqKjX"},"source":["## Test images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqiVg3zEYFth"},"outputs":[],"source":["mfds = estimate_fractal_dimension(testimg_history, saveas=f'{output_path}/test/mfd.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for ii, impair in enumerate(testimg_history):\n","    image, mnmx = impair\n","    boundy = extract_edges(image)\n","    fig, ax = plt.subplots(1, 2, figsize=figsize, sharey=True)\n","    ax[0].imshow(boundy)\n","    ax[1].text(0, 0, ps.metrics.boxcount(boundy), verticalalignment='top')\n","    ax[1].axis('off')\n","    plt.savefig(f'{output_path}/test/border_zoom{ii}.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.close('all')\n","\n","for ii, impair in enumerate(testimg_history):\n","    image, mnmx = impair\n","    newmnmx = None\n","    if ii < len(testimg_history)-1:\n","        newmnmx = testimg_history[ii+1][1]\n","    str_ii = f\"{ii:02}\"\n","    letter_dim = \"$median(D_{frac})$\"\n","    \n","    show_img(image, mnmx, newmnmx=newmnmx, handler=False, title=f'{letter_dim}={mfds[ii]:.6f}', savename=f'{output_path}/test/lossmap_zoom{ii}.png')\n","    plt.tight_layout()\n"]},{"cell_type":"markdown","metadata":{"id":"GrW2rUkvqr_4"},"source":["# Generate a movie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwP2VoByqucJ"},"outputs":[],"source":["train_hist_video = zoom_out_sequence(trainimg_history[-1], growth_factor=2.)\n","test_hist_video = zoom_out_sequence(testimg_history[-1], growth_factor=2.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpZGes88YFth"},"outputs":[],"source":["train_hist_video[0][0][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGuXHVwoq1I4"},"outputs":[],"source":["# each call to increase_resolution increases the resolution of one image and\n","# returns True, or returns False if all images are at or exceed the target resolution\n","while increase_resolution(train_hist_video, test_hist_video, 8):\n","    with open(f'{output_path}/train/{canonical_name(None)}.pickle', 'wb') as handle:\n","        pickle.dump(train_hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    with open(f'{output_path}/test/{canonical_name(None)}.pickle', 'wb') as handle:\n","        pickle.dump(test_hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","ts = 30\n","# train animation\n","anim = make_animator(train_hist_video, timesteps_per_transition=ts*2)\n","anim.save(f'{output_path}/train/{canonical_name(None)}.mp4',fps=ts, dpi=dpi)\n","#test animation\n","anim = make_animator(test_hist_video, timesteps_per_transition=ts*2)\n","anim.save(f'{output_path}/test/{canonical_name(None)}.mp4',fps=ts, dpi=dpi)\n","\n","# officially end\n","plt.close('all')\n","send_alram(\"Finally all over!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4Zzh6g6YFth"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
