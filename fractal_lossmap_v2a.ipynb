{"cells":[{"cell_type":"markdown","metadata":{"id":"InosSXqlwUL4"},"source":["# Loading libraries"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3-C8YNzAwKQx"},"outputs":[],"source":["# GPU settings\n","import os\n","os.environ['XLA_FLAGS'] = '--xla_force_host_platform_device_count=4'\n","# os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n","# os.environ['CUDA_VISIBLE_DEVICES'] = '0,1,2,4'\n","\n","# Computation settings\n","import jax\n","from jax import lax, random, config, numpy as jnp\n","# config.update('jax_enable_x64', True)   # for double precision, but cannot run convolution!\n","\n","\n","import porespy as ps\n","import numpy as np\n","\n","# Plotting settings\n","import matplotlib\n","# from google.colab import output\n","# output.enable_custom_widget_manager()\n","# %matplotlib ipympl\n","import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","import matplotlib.animation as animation\n","from matplotlib import cm\n","\n","# ETC\n","# import asyncio\n","# import telegram\n","import pickle\n","import math\n","import datetime\n","from functools import partial\n","from typing import Callable, Any\n","from pprint import pprint\n","\n","from tqdm import tqdm\n","from datetime import datetime\n","from pytz import timezone\n","from collections import deque\n","\n","record_t = datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d_%H%M')[2:]\n","# TOKEN = '6740952693:AAFOUwNFVu2O3Bpf7nlKwIlDzyNaarN7Fl8'\n","# CHAT_ID = '5110804803'\n","# msg = f\"Lossmap was generated!\\nPlease check and zoom it!\"\n","\n","# bot = telegram.Bot(TOKEN)\n","# def send_alram(msg=msg):\n","#     return bot.sendMessage(chat_id=CHAT_ID, text=msg)"]},{"cell_type":"markdown","metadata":{"id":"akdQkfkpAsO9"},"source":["# Hyperparams"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yShvfJzA_8XU"},"outputs":[],"source":["# Model\n","width = 4\n","hidden_depth = 1\n","target_dim = 10\n","num_epochs = 5\n","nonlinearity = 'relu'\n","\n","# Datset\n","batch_size = 32\n","# minibatch_size = None\n","default_outer_batch_size = 16\n","\n","# Plotting\n","# phase_space = 'paraminit_vs_lr'\n","mnmx = [-4, 0, -4, 0]\n","# mnmx = [-4, -3, -1, 1]\n","\n","default_resolution = 16\n","dpi = 100\n","figsize = (16, 8)\n","interactive_gui = True\n","\n","if interactive_gui:\n","    ## interactive plotting\n","    # from google.colab import output\n","    # output.enable_custom_widget_manager()\n","    %matplotlib ipympl\n","else:\n","    matplotlib.use('Agg')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jnFWa394BIR9"},"outputs":[],"source":["def canonical_name(i=None, record_t=record_t):\n","    \"\"\"\n","    turn hyperparameters in the previous cell into a canonical base filename to\n","    use for this experimental condition\n","    \"\"\"\n","    return f'SN_zoom_{i if i is not None else \"\"}_W-(784x{width}, {width}x{target_dim})_activation-{nonlinearity}_epochs-{num_epochs}_batchsize-{batch_size}_resolution-{default_resolution}_time-{record_t}'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S8gcL3ntLx46"},"outputs":[],"source":["# Make the save directory\n","from datetime import datetime\n","from pytz import timezone\n","record_t = datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d_%H%M%S')[2:]\n","output_path = f\"./output/{canonical_name(None)}\"\n","os.makedirs(output_path + \"/train\", exist_ok=True)\n","os.makedirs(output_path + \"/test\", exist_ok=True)\n","# os.makedirs(output_path + \"/lossacc\", exist_ok=True)"]},{"cell_type":"markdown","metadata":{"id":"36XJLykLBgzk"},"source":["# Modeling"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from model.shallownet import *\n","from plot.trendline import plot_trend\n","from collections import deque\n","\n","def split_and_train(theta, hparams, batches, tbatches, num_epochs, outer_batch_size=None):\n","    global tile_batch, zoom_seq\n","    global loss_deque, tloss_deque, acc_deque, tacc_deque, minloss_global\n","\n","\n","    if outer_batch_size is None:\n","        outer_batch_size = default_outer_batch_size\n","\n","    # Theta initialization\n","    if theta is None:\n","        theta = init(42, width, hidden_depth)\n","\n","    # Cut off the learning rates as bite size\n","    bs = hparams.shape[0]\n","    if bs > outer_batch_size:\n","        train_loss1, test_loss1 = split_and_train(theta, hparams[:bs//2, ], batches, tbatches, num_epochs)\n","        train_loss2, test_loss2 = split_and_train(theta, hparams[bs//2:, ], batches, tbatches, num_epochs)\n","        return jnp.concatenate((train_loss1, train_loss2), axis=0), jnp.concatenate((test_loss1, test_loss2), axis=0)\n","\n","    # Train session\n","    _theta = jax.tree_map(lambda u: jnp.tile(u, (bs,) + (1,) * len(u.shape)), theta)\n","    loss_archive, acc_archive, tloss_archive, tacc_archive = train(_theta, hparams, batches, tbatches, num_epochs)\n","\n","    # TOP5 ranking\n","    def min_tournament(loss_archive):\n","        loss_arr = np.array(loss_archive).T\n","        minloss = loss_arr[:, -20:].mean(axis=1)\n","        px_minloss = minloss.argmin()\n","        minloss = minloss.min()\n","        return px_minloss, minloss\n","\n","    # loss_arr = np.array(loss_archive).T  # (px, epoch)\n","    # minloss = loss_arr[:, -20:].mean(axis=1)\n","    # px_minloss = minloss.argmin()\n","    # minloss = minloss.min()\n","\n","    # Find the well-converged train loss and get them up!\n","    px_minloss, minloss = min_tournament(loss_archive)\n","    loss_arr = np.array(loss_archive).T\n","    acc_arr = np.array(acc_archive).T\n","    tloss_arr = np.array(tloss_archive).T\n","    tacc_arr = np.array(tacc_archive).T\n","\n","    if minloss_global > minloss:\n","        minloss_global = minloss\n","        px = (tile_batch - 1) * default_outer_batch_size + px_minloss\n","        loss_deque.appendleft({f\"{px}\": loss_arr[px_minloss]})\n","        acc_deque.appendleft({f\"{px}\": acc_arr[px_minloss]})\n","        tloss_deque.appendleft({f\"{px}\": tloss_arr[px_minloss]})\n","        tacc_deque.appendleft({f\"{px}\": tacc_arr[px_minloss]})\n","\n","    return convergence_measure(jnp.stack(loss_archive, axis=-1)), convergence_measure(jnp.stack(tloss_archive, axis=-1))    # stack-->(16, 100), convergence_measure-->(...?)\n","\n","\n","# Trainining session\n","def train(_theta, hparams, batches, tbatches, num_epochs):\n","    global tile_batch\n","    tile_batch += 1\n","\n","    # theta_archive = []\n","    loss_archive = []\n","    acc_archive = []\n","    tloss_archive = []\n","    tacc_archive = []\n","\n","    # Training\n","    desc = f'[Tile {tile_batch}/{math.ceil(default_resolution**2/default_outer_batch_size)}] Training-epochs: '\n","    for _ in tqdm(range(num_epochs), total=num_epochs, desc=desc, leave=False):\n","        # Need to divide X and Y as each batch.\n","        loss_epoch = 0. # broadcasting --> (16,)\n","        acc_epoch = 0.\n","        for batch in batches.as_numpy_iterator():\n","            _theta, _loss, _acc = train_step(_theta, hparams, batch)\n","            loss_epoch += _loss\n","            acc_epoch += _acc\n","        loss_epoch /= total_batch   # (16,)\n","        acc_epoch /= total_batch\n","        # theta_archive.append(_theta)        # [(16, 784, 300), (16,), (16,), (16, 300, 10)] * 100\n","        loss_archive.append(loss_epoch)     # [(16,)] * 100\n","        acc_archive.append(acc_epoch.astype(float))\n","\n","        # Validating during epochs\n","        tloss_epoch = 0.\n","        tacc_epoch = 0.\n","        for tbatch in tbatches.as_numpy_iterator():\n","            _, _tloss, _tacc = eval_step(_theta, tbatch)\n","            tloss_epoch += _tloss\n","            tacc_epoch += _tacc\n","        tloss_epoch /= total_tbatch\n","        tacc_epoch /= total_tbatch\n","        tloss_archive.append(tloss_epoch)\n","        tacc_archive.append(tacc_epoch.astype(float))\n","\n","    # # Validating after training\n","    # tloss_archive = []\n","    # tacc_archive = []\n","    # tloss = 0.\n","    # tacc = 0.\n","    # for tbatch in tbatches.as_numpy_iterator():\n","    #     _, _tloss, _tacc = eval_step(_theta, tbatch)\n","    #     tloss += _tloss\n","    #     tacc += _tacc\n","    # tloss /= total_tbatch\n","    # tacc /= total_tbatch\n","    # tloss_archive.append(tloss)\n","    # tacc_archive.append(tacc.astype(float))\n","\n","    return loss_archive, acc_archive, tloss_archive, tacc_archive\n","\n","# Compensator\n","@partial(jax.vmap, in_axes=(0,), out_axes=0)\n","def convergence_measure(v, max_val=1e6):\n","    fin = jnp.isfinite(v)\n","    v = v * fin + max_val * (1-fin)\n","    v /= v[0]\n","    exceeds = (v > max_val)\n","    v = v * (1-exceeds) + max_val * exceeds\n","    converged = (jnp.mean(v[-20:]) < 1)\n","    # return jnp.where(converged, -jnp.sum(v), jnp.sum(1/v)) / v.shape[0]  # All-epochs summation loss\n","    return -(1-jnp.mean(v))\n","\n","    # return 1 - jnp.clip(jnp.mean(v), 0., 1.)\n"]},{"cell_type":"markdown","metadata":{"id":"szLdaCvzhItA"},"source":["# Plotting and Measure the Fractal Dimension"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GxkGz1-whK3-"},"outputs":[],"source":["# Generate the lossmap\n","def gen_img(mnmx, resolution=None):\n","    \"\"\"\n","    generate an image of the hyperparameter landscape,\n","    for a range of hyperparameter values specified by mnmx\n","    \"\"\"\n","    global zoom_seq, loss_deque, tloss_deque, acc_deque, tacc_deque, minloss_global\n","\n","    loss_deque = deque(maxlen=5)\n","    tloss_deque = deque(maxlen=5)\n","    acc_deque = deque(maxlen=5)\n","    tacc_deque = deque(maxlen=5)\n","\n","    minloss_global = np.float32('inf')\n","\n","    if resolution is None:\n","        resolution = default_resolution\n","\n","    mn1, mx1, mn2, mx2 = mnmx\n","    gg1 = jnp.logspace(mn1, mx1, resolution)\n","    gg2 = jnp.logspace(mn2, mx2, resolution)\n","    lr0, lr1 = jnp.meshgrid(gg2, gg1)\n","    lr = jnp.stack([lr0.ravel(), lr1.ravel()], axis=-1)\n","\n","    V, tV = split_and_train(\n","        theta=None,\n","        hparams=lr,\n","        batches=train_ds,\n","        tbatches=test_ds,\n","        num_epochs=num_epochs\n","        )\n","    \n","    # plot the loss trend\n","    plot_trend(loss_deque, ylabel='Loss', saveas=f'{output_path}/train/convTOP5_loss_zoom{zoom_seq}.png')\n","    plot_trend(acc_deque, ylabel='Acc', saveas=f'{output_path}/train/convTOP5_acc_zoom{zoom_seq}.png')\n","    plot_trend(tloss_deque, ylabel='Loss', saveas=f'{output_path}/test/convTOP5_vloss_zoom{zoom_seq}.png')\n","    plot_trend(tacc_deque, ylabel='Acc', saveas=f'{output_path}/test/convTOP5_vacc_zoom{zoom_seq}.png')\n","\n","\n","    V = V.reshape((resolution, resolution))\n","    tV = tV.reshape((resolution, resolution))\n","\n","\n","    # send_alram(msg=msg)\n","\n","\n","    return V, tV\n","\n","\n","# Measure the fractal dim\n","def extract_edges(X):\n","    \"\"\"\n","    define edges as sign changes in the scalar representing convergence or\n","    divergence rate -- on one side of the edge training converges,\n","    while on the other side of the edge training diverges\n","    \"\"\"\n","\n","    Y = jnp.stack((X[1:,1:], X[:-1,1:], X[1:,:-1], X[:-1,:-1]), axis=-1)\n","    Z = jnp.sign(jnp.max(Y, axis=-1)*jnp.min(Y, axis=-1))\n","    return Z<0\n","\n","def estimate_fractal_dimension(hist_video, show_plot=True, saveas=None):\n","    if show_plot:\n","        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 4))\n","        ax1.set_yscale('log')\n","        ax1.set_xscale('log')\n","        ax1.set_xlabel('box edge length')\n","        ax1.set_ylabel('number of boxes spanning phases')\n","        ax2.set_xlabel('box edge length')\n","        ax2.set_ylabel('slope')\n","        ax2.set_xscale('log')\n","\n","    mfds = []\n","    for n, U in enumerate(hist_video):\n","        edge = extract_edges(U[0])\n","        bc = ps.metrics.boxcount(edge)\n","        mfd = np.median(bc.slope)\n","        mfds.append(mfd)\n","        print(f'Median fractal dimension: {mfd} at zoom{n}')\n","\n","        if show_plot:\n","            ax1.plot(bc.size, bc.count, '-o', alpha=0.7, label=f'Zoom{n}, mfd={mfd:.3f}')\n","            ax2.plot(bc.size, bc.slope, '-o', alpha=0.7, label=f'Zoom{n}, mfd={mfd:.3f}')\n","    \n","    if saveas:\n","        plt.legend()\n","        plt.savefig(saveas)\n","\n","    return mfds\n","\n","# Interploating\n","def cdf_img(x, x_ref, buffer=0.25):\n","    \"\"\"\n","    rescale x, relative to x_ref (x_ref is often the same as x), to achieve a uniform\n","    distribution over values with positive and negative intensities, but also to\n","    preserve the sign of x. This makes for a visualization that shows more\n","    structure.\n","    \"\"\"\n","    u = jnp.sort(x_ref.ravel())\n","    num_neg = jnp.sum(u<0)\n","    num_nonneg = u.shape[0] - num_neg\n","    v = jnp.concatenate((jnp.linspace(-1,-buffer,num_neg), jnp.linspace(buffer,1,num_nonneg)), axis=0)\n","    y = jnp.interp(x, u, v)\n","    return -y\n","\n","\n","# Notation\n","def truncate_sci_notation(numbers):\n","    \"\"\"\n","    keeping enough significant digits that the\n","    numbers disagree in four digits\n","    \"\"\"\n","\n","    # Convert numbers to scientific notation\n","    n1_sci, n2_sci = \"{:.15e}\".format(numbers[0]), \"{:.15e}\".format(numbers[1])\n","\n","    # Extract the significant parts and exponents\n","    sig_n1, exp_n1 = n1_sci.split('e')\n","    sig_n2, exp_n2 = n2_sci.split('e')\n","\n","    # Find the first position at which they disagree\n","    min_len = min(len(sig_n1), len(sig_n2))\n","    truncate_index = min_len\n","\n","    for i in range(min_len):\n","        if (sig_n1[i] != sig_n2[i]) or (exp_n1 != exp_n2):\n","            # +4 accounts for 4 digits after the first disagreement\n","            truncate_index = i + 4\n","            if i == 0:\n","                truncate_index += 1 # Account for decimal point\n","        break\n","\n","    exp_n1 = exp_n1[0] + exp_n1[2]\n","    exp_n2 = exp_n2[0] + exp_n2[2]\n","    if (exp_n1 == \"+00\") and (exp_n2 == \"+00\"):\n","        # don't bother with scientific notation if exponent is 0\n","        return [sig_n1[:truncate_index], sig_n2[:truncate_index]]\n","\n","    # Truncate and reconstruct the scientific notation\n","    truncated_n1 = \"{}e{}\".format(sig_n1[:truncate_index], exp_n1)\n","    truncated_n2 = \"{}e{}\".format(sig_n2[:truncate_index], exp_n2)\n","\n","    return [truncated_n1, truncated_n2]\n","\n","def tickslabels(mnmx):\n","    return mnmx, truncate_sci_notation(10.**np.array(mnmx))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MrJfi2LYjceH"},"outputs":[],"source":["# Animating zoom sequences and interpolating between frames\n","def zoom_out_sequence(hist_final, growth_factor=2., max_scale=6):\n","  \"\"\"\n","  generate a sequence of (image, bounds) zooming out from the (image, bounds) in hist_final\n","  \"\"\"\n","\n","  image, mnmx = hist_final\n","\n","  cT = np.array([(mnmx[0] + mnmx[1])/2., (mnmx[2] + mnmx[3])/2.])\n","  wT = np.array([mnmx[1] - mnmx[0], mnmx[3] - mnmx[2]])\n","\n","  hist = [(image, mnmx)]\n","  w_scale = 1.\n","  while np.min(wT * w_scale) < max_scale:\n","    w_scale *= 2\n","    mnmx = [\n","        cT[0] - w_scale * wT[0]/2.,\n","        cT[0] + w_scale * wT[0]/2.,\n","        cT[1] - w_scale * wT[1]/2.,\n","        cT[1] + w_scale * wT[1]/2.,\n","    ]\n","    hist.insert(0, (np.zeros((2,2)), mnmx))\n","\n","  return hist\n","\n","def increase_resolution(history, target_res):\n","  \"\"\"\n","  Increase the resolution of images of a fractal landscape that we've already\n","  generated.\n","\n","  Find the first entry in history with resolution below target_res, and increase\n","  its resolution. If all images are already at least the target resolution,\n","  return False.\n","  \"\"\"\n","\n","  new_h = []\n","  for ii in range(len(history)):\n","    h = history[ii]\n","    image, mnmx = h\n","    if image.shape[0] < target_res:\n","      current_time = datetime.datetime.now()\n","      print( f\"increasing resolution of {ii} / {len(history)} at {current_time}, current resolution is {image.shape}\")\n","      image = gen_img(mnmx, resolution=target_res)\n","      history[ii] = (image, mnmx)\n","      return True\n","  return False\n","\n","def interpolate_history(hist1, hist2, alpha):\n","  \"\"\"\n","  get the mnmx (hyperparameter bounding box) value for a fraction alpha between\n","  two images\n","  \"\"\"\n","\n","  _, mnmx1 = hist1\n","  _, mnmx2 = hist2\n","\n","  if alpha == 0:\n","    # avoid NaNs on very last frame\n","    return mnmx1\n","\n","  w1 = np.array([mnmx1[1] - mnmx1[0], mnmx1[3] - mnmx1[2]])\n","  w2 = np.array([mnmx2[1] - mnmx2[0], mnmx2[3] - mnmx2[2]])\n","  c1 = np.array([(mnmx1[0] + mnmx1[1])/2, (mnmx1[2] + mnmx1[3])/2])\n","  c2 = np.array([(mnmx2[0] + mnmx2[1])/2, (mnmx2[2] + mnmx2[3])/2])\n","\n","  gamma = np.exp((1-alpha)*0 + alpha*np.log(w2/w1))\n","\n","  # ct = cstar + (c1 - cstar)*gamma\n","  # c1 = cstar + (c1 - cstar)*1\n","  # c2 = cstar + (c1 - cstar)*w2/w1\n","  cstar = (c2 - c1*w2/w1) / (1 - w2 / w1)\n","\n","  ct = cstar + (c1 - cstar)*gamma\n","  hwt = gamma*w1\n","\n","  return [ct[0] - hwt[0]/2, ct[0] + hwt[0]/2, ct[1] - hwt[1]/2, ct[1] + hwt[1]/2]\n","\n","\n","def em(extent_rev):\n","  return [extent_rev[2], extent_rev[3], extent_rev[0], extent_rev[1]]\n","\n","def make_animator(history, timesteps_per_transition=60, reference_scale=None, cmap='Spectral'):\n","\n","  fig, ax, im1 = show_img(history[0][0], history[0][1], newmnmx=None,\n","                          handler=False, reference_scale=reference_scale, cmap=cmap)\n","\n","  im2 = ax.imshow(\n","      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n","      vmin = -1, vmax = 1,\n","      cmap=cmap,\n","      aspect='auto',\n","      interpolation='nearest'\n","      )\n","\n","  im3 = ax.imshow(\n","      jnp.zeros_like(history[1][0]), extent=em(history[1][1]), origin='lower',\n","      vmin = -1, vmax = 1,\n","      cmap=cmap,\n","      aspect='auto',\n","      interpolation='nearest'\n","      )\n","\n","  def animate(n):\n","    hist_index = n // timesteps_per_transition\n","    alpha = (n % timesteps_per_transition) / timesteps_per_transition\n","\n","    hist1 = history[hist_index]\n","    if hist_index >= len(history)-1:\n","      hist2 = hist1 # very last frame\n","    else:\n","      hist2 = history[hist_index+1]\n","    if hist_index >= len(history)-2:\n","      hist3 = hist2 # very last frame\n","    else:\n","      hist3 = history[hist_index+2]\n","\n","    lims = interpolate_history(hist1, hist2, alpha)\n","\n","    # interpolation scheme for image restretch / colormap\n","    alpha_area = jnp.sin(alpha*np.pi/2)**2\n","\n","    print(f'frame {n} / {timesteps_per_transition*len(history)}, zoom step {hist_index} / {len(history)}', end='\\r', flush=True)\n","\n","    img_1 = (1-alpha_area)*cdf_img(hist1[0], hist1[0]) + alpha_area*cdf_img(hist1[0], hist2[0])\n","    img_2 = (1-alpha_area)*cdf_img(hist2[0], hist1[0]) + alpha_area*cdf_img(hist2[0], hist2[0])\n","    img_3 = (1-alpha_area)*cdf_img(hist3[0], hist1[0]) + alpha_area*cdf_img(hist3[0], hist2[0])\n","\n","    im1.set_data(img_1)\n","    im1.set_extent(em(hist1[1]))\n","    im2.set_data(img_2)\n","    im2.set_extent(em(hist2[1]))\n","    im3.set_data(img_3)\n","    im3.set_extent(em(hist3[1]))\n","    im3.set_alpha(alpha)\n","\n","    ax.set_ylim(lims[0], lims[1])\n","    ax.set_xlim(lims[2], lims[3])\n","\n","    # Set the new tick positions\n","    ax.set_xticks(*tickslabels([lims[2], lims[3]]))\n","    ax.set_yticks(*tickslabels([lims[0], lims[1]]), rotation=90)\n","\n","    labels = ax.get_xticklabels()\n","    labels[0].set_horizontalalignment('left')\n","    labels[1].set_horizontalalignment('right')\n","    labels = ax.get_yticklabels()\n","    labels[0].set_verticalalignment('bottom')\n","    labels[1].set_verticalalignment('top')\n","\n","    return fig,\n","\n","  anim = animation.FuncAnimation(fig,animate,frames=timesteps_per_transition*(len(history)-1)+1, repeat=False)\n","  return anim"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4rKdJxPsUfnF"},"outputs":[],"source":["# Interactive plotting\n","cids = []\n","click_event = [None]\n","\n","def onclick(event):\n","    click_event[0] = (event.xdata, event.ydata)\n","\n","def onrelease(event, fig, im, rect, mnmx, img, recalculate_image=True):\n","    global tile_batch, zoom_seq\n","    tile_batch = 0\n","    zoom_seq += 1\n","    \n","    if click_event[0] is None:\n","        return\n","\n","    e0 = [click_event[0][0], event.xdata]\n","    e1 = [click_event[0][1], event.ydata]\n","\n","    for v in e0+e1:\n","        if v is None:\n","            return\n","\n","    newmnmx = [np.min(e1), np.max(e1), np.min(e0), np.max(e0)]\n","\n","    min_w = (mnmx[1] - mnmx[0])/20\n","    if newmnmx[1] - newmnmx[0] < min_w:\n","        c = (newmnmx[1] + newmnmx[0])/2.\n","        newmnmx[0] = c - min_w/2\n","        newmnmx[1] = c + min_w/2\n","    min_w = (mnmx[3] - mnmx[2])/20\n","\n","    if newmnmx[1] - newmnmx[0] < min_w:\n","        c = (newmnmx[3] + newmnmx[2])/2.\n","        newmnmx[2] = c - min_w/2\n","        newmnmx[3] = c + min_w/2\n","\n","    for v in newmnmx:\n","        if v is None:\n","            return\n","\n","    plot_img(img, mnmx, newmnmx, fig=fig, im=im, rect=rect)\n","    plt.draw()\n","\n","    if recalculate_image:\n","        click_event[0] = None\n","        mnmx = newmnmx\n","        img = gen_img(mnmx)\n","        plot_img(img, mnmx, None, fig=fig, im=im, rect=rect)\n","\n","\n","def plot_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n","             handler=True, savename=None,\n","             reference_scale=None,\n","             cmap='Spectral',\n","             title=\"\"\n","             ):\n","\n","    global loss_deque, acc_deque, tloss_deque, tacc_deque, default_outer_batch_size\n","\n","    mn1, mx1, mn2, mx2 = mnmx\n","    trainimg, testimg = image\n","\n","    if reference_scale is None:\n","        reference_scale_train = trainimg\n","        reference_scale_test = testimg\n","\n","\n","    trainimg = cdf_img(trainimg, reference_scale_train)\n","    testimg = cdf_img(testimg, reference_scale_test)\n","\n","    # ax1 = None\n","    if im is not None:\n","        im1, im2 = im\n","\n","    if fig is None:\n","        # fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi, sharey=True, constrained_layout=True)\n","        fig, ax = plt.subplots(1, 2, figsize=figsize, dpi=dpi, sharey=True)\n","\n","        ax = ax.flatten()\n","        im1 = ax[0].imshow(trainimg,\n","                        extent=[mn2, mx2, mn1, mx1],\n","                        origin='lower',\n","                        vmin=-1, vmax=1,\n","                        cmap=cmap,\n","                        aspect='auto',\n","                        interpolation='nearest'\n","                        )\n","        im2 = ax[1].imshow(testimg,\n","                        extent=[mn2, mx2, mn1, mx1],\n","                        origin='lower',\n","                        vmin=-1, vmax=1,\n","                        cmap=cmap,\n","                        aspect='auto',\n","                        interpolation='nearest'\n","                        )\n","        # fig.colorbar(im1, ax=ax.ravel().tolist())\n","        if title == \"\":\n","            batch_text = f\"{num_epochs} epochs, {batch_size} batches\"\n","            title = f'Trainability dependence on parameter initialization and learning rate\\nW[(784,{width}), ({width},10)], {nonlinearity}, {batch_text}'\n","        fig.suptitle(title)\n","\n","        fig.supxlabel('Input layer weight offset')\n","        fig.supylabel('Learning rate')\n","\n","        rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","        ax[0].add_patch(rect)\n","        rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","        ax[1].add_patch(rect)\n","\n","    im1.set_extent([mn2, mx2, mn1, mx1])\n","    im1.set_data(trainimg)\n","    im2.set_extent([mn2, mx2, mn1, mx1])\n","    im2.set_data(testimg)\n","\n","    # Set the new tick positions on the x-axis\n","    # aaxx = plt.gca()\n","    ax = fig.axes\n","    ax[0].set_title(\"Training Lossmap\")\n","    ax[1].set_title(\"Evaluating Lossmap\")\n","\n","    for nn, aaxx in enumerate(ax):\n","        aaxx.set_xticks(*tickslabels([mn2, mx2]))\n","        aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n","\n","        labels = aaxx.get_xticklabels()\n","        labels[0].set_horizontalalignment('left')\n","        labels[1].set_horizontalalignment('right')\n","        if nn == 0:\n","            labels = aaxx.get_yticklabels()\n","            labels[0].set_verticalalignment('bottom')\n","            labels[1].set_verticalalignment('top')\n","\n","    if handler and (newmnmx is None):\n","        trainimg_history.append((trainimg, mnmx))\n","        testimg_history.append((testimg, mnmx))\n","\n","\n","    if newmnmx:\n","        mn1, mx1, mn2, mx2 = newmnmx\n","    rect.set_xy((mn2, mn1))\n","    rect.set_width(mx2-mn2)\n","    rect.set_height(mx1-mn1)\n","\n","    if handler:\n","        while len(cids) > 0:\n","            fig.canvas.mpl_disconnect(cids.pop())\n","\n","    def onrelease_partial(event):\n","        return onrelease(event, fig, im, rect, mnmx, img)\n","    def onmotion_partial(event):\n","        return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n","\n","    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n","    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n","    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n","\n","    # plt.tight_layout()\n","\n","    im = (im1, im2)\n","    plt.draw()\n","\n","    if savename:\n","        plt.savefig(savename)\n","\n","    # Star-patch\n","    for rank, px in enumerate(loss_deque):\n","        patch_coord = [(int(k) % default_resolution, int(k) // default_resolution) for k, _ in px.items()][0]\n","        ax[0].text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax[0].transAxes)\n","        ax[1].text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax[1].transAxes)\n","\n","\n","    return fig, ax, im\n","\n","\n","def increase_resolution(train_history, test_history, target_res):\n","  \"\"\"\n","  Increase the resolution of images of a fractal landscape that we've already\n","  generated.\n","\n","  Find the first entry in history with resolution below target_res, and increase\n","  its resolution. If all images are already at least the target resolution,\n","  return False.\n","  \"\"\"\n","\n","  new_h = []\n","  for ii in range(len(train_history)):\n","    train_h = train_history[ii]\n","    test_h = test_history[ii]\n","\n","    train_image, train_mnmx = train_h\n","    test_image, test_mnmx = test_h\n","\n","    if train_image.shape[0] < target_res:\n","      current_time = datetime.now()\n","      print( f\"increasing resolution of {ii} / {len(train_history)} at {current_time}, current resolution is {train_image.shape}\")\n","      train_image, test_image = gen_img(train_mnmx, resolution=target_res)\n","      train_history[ii] = (train_image, train_mnmx)\n","      test_history[ii] = (test_image, test_mnmx)\n","\n","      return True\n","  return False\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RLsWZXMIpeQZ"},"outputs":[],"source":["def show_img(image, mnmx, newmnmx=None, fig=None, im=None, rect=None,\n","             handler=True, savename=None,\n","             reference_scale=None,\n","             cmap='Spectral_r',\n","             title=\"\"\n","             ):\n","  \n","  global loss_deque, acc_deque, tloss_deque, tacc_deque, default_outer_batch_size\n","  \n","  mn1, mx1, mn2, mx2 = mnmx\n","\n","  if reference_scale is None:\n","    reference_scale = image\n","\n","  image = cdf_img(image, reference_scale)\n","\n","  ax1 = None\n","  if fig is None:\n","    fig, (ax1) = plt.subplots(figsize=(figsize[0]/2, figsize[1]), dpi=dpi)\n","    im = ax1.imshow(image,\n","                    extent=[mn2, mx2, mn1, mx1],\n","                    origin='lower',\n","                    vmin=-1, vmax=1,\n","                    cmap=cmap,\n","                    aspect='auto',\n","                    interpolation='nearest'\n","                    )\n","    fig.colorbar(im, ax=ax1)\n","\n","    if title == \"\":\n","      batch_text = f\"{num_epochs} epochs, {batch_size} batches\"\n","      title = f'Trainability dependence on parameter initialization and learning rate\\nW[({width},{width}), ({width},10)], {nonlinearity}, {batch_text}'\n","    fig.suptitle(title)\n","   \n","    ax1.set_ylabel('Learning rate')\n","    ax1.set_xlabel('Input layer weight offset')\n","\n","    rect = patches.Rectangle((mn2, mn1), mx2-mn2, mx1-mn1, linewidth=1, edgecolor='r', facecolor='none')\n","    ax1.add_patch(rect)\n","\n","  im.set_extent([mn2, mx2, mn1, mx1])\n","  im.set_data(image)\n","\n","  # Set the new tick positions on the x-axis\n","  aaxx = plt.gca()\n","  aaxx.set_xticks(*tickslabels([mn2, mx2]))\n","  aaxx.set_yticks(*tickslabels([mn1, mx1]), rotation=90)\n","\n","  labels = aaxx.get_xticklabels()\n","  labels[0].set_horizontalalignment('left')\n","  labels[1].set_horizontalalignment('right')\n","  labels = aaxx.get_yticklabels()\n","  labels[0].set_verticalalignment('bottom')\n","  labels[1].set_verticalalignment('top')\n","\n","  if handler and (newmnmx is None):\n","    image_history.append((image, mnmx))\n","\n","  if newmnmx:\n","    mn1, mx1, mn2, mx2 = newmnmx\n","  rect.set_xy((mn2, mn1))\n","  rect.set_width(mx2-mn2)\n","  rect.set_height(mx1-mn1)\n","\n","  if handler:\n","    while len(cids) > 0:\n","      fig.canvas.mpl_disconnect(cids.pop())\n","\n","    def onrelease_partial(event):\n","      return onrelease(event, fig, im, rect, mnmx, img)\n","    def onmotion_partial(event):\n","      return onrelease(event, fig, im, rect, mnmx, img, recalculate_image=False)\n","\n","    cids.append(fig.canvas.mpl_connect('button_press_event', onclick))\n","    cids.append(fig.canvas.mpl_connect('button_release_event', onrelease_partial))\n","    # cids.append(fig.canvas.mpl_connect('motion_notify_event', onmotion_partial))\n","\n","  # plt.tight_layout()\n","  plt.draw()\n","\n","  if savename:\n","    plt.savefig(savename)\n","  \n","  for rank, px in enumerate(loss_deque):\n","    patch_coord = [(int(k) % default_resolution, int(k) // default_resolution) for k, _ in px.items()][0]\n","    ax1.text(patch_coord[0]/default_resolution, patch_coord[1]/default_resolution, f'#{rank+1}\\n★', verticalalignment='bottom', horizontalalignment='center', transform=ax1.transAxes)\n","  savename_marked = savename.split('.')\n","  savename_marked[0] = savename_marked[0] + \"_starred\"\n","  savename_marked = \".\".join(savename_marked)\n","  plt.savefig(savename_marked)\n","  \n","\n","  return fig, ax1, im"]},{"cell_type":"markdown","metadata":{"id":"esuAL5tAit2N"},"source":["# Generating the lossmap"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"B2R7QrxQladt"},"outputs":[{"name":"stdout","output_type":"stream","text":["WARNING:tensorflow:From c:\\Users\\konyang\\anaconda3\\envs\\ATTNtorch\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n","\n","600\n","100\n"]}],"source":["from datasets.mnist import *\n","batch_size = 100\n","train_ds = data_normalize(train_ds).shuffle(buffer_size=10, seed=42).batch(batch_size).prefetch(1)\n","test_ds = data_normalize(test_ds).shuffle(buffer_size=10, seed=42).batch(batch_size).prefetch(1)\n","\n","total_batch = train_ds.cardinality().numpy()\n","total_tbatch = test_ds.cardinality().numpy()\n","\n","print(total_batch)\n","print(total_tbatch)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":391},"executionInfo":{"elapsed":94382,"status":"error","timestamp":1711987939194,"user":{"displayName":"J U","userId":"09528049220557542940"},"user_tz":-540},"id":"H3r5KDHEhEeu","outputId":"5eb04283-2918-49e5-88ad-e9f48c8c0345"},"outputs":[],"source":["# Get the lossmap\n","output_path = f\"./output/{canonical_name()}\"\n","tile_batch = 0\n","zoom_seq = 0\n","loss_deque = deque(maxlen=50)\n","acc_deque = deque(maxlen=50)\n","tloss_deque = deque(maxlen=50)\n","tacc_deque = deque(maxlen=50)\n","minloss_global = 0.\n","\n","# send_alram(msg=\"Start training.\")\n","\n","cids = []\n","click_event = [None]\n","trainimg_history = []\n","testimg_history = []\n","img = gen_img(mnmx)\n","\n","plt.close('all')\n","plt.ion()\n","# plot_img(img, mnmx, None, savename=f\"{output_path}/{canonical_name(record_t=datetime.now(timezone('Asia/Seoul')).strftime('%Y%m%d_%H%M')[2:])}.png\")\n","plot_img(img, mnmx, None)\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from pprint import pprint\n","pprint(loss_deque)\n","pprint(acc_deque)"]},{"cell_type":"markdown","metadata":{"id":"jDC1ScCLooXL"},"source":["# Show all the generated images"]},{"cell_type":"markdown","metadata":{"id":"eIZ9VZzJqIaz"},"source":["## Train images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tJLrAXi9YFtg"},"outputs":[],"source":["mfds = estimate_fractal_dimension(trainimg_history, saveas=f'{output_path}/train/mfd.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.close('all')\n","\n","for ii, impair in enumerate(trainimg_history):\n","    image, mnmx = impair\n","    newmnmx = None\n","    if ii < len(trainimg_history)-1:\n","        newmnmx = trainimg_history[ii+1][1]\n","    str_ii = f\"{ii:02}\"\n","    letter_dim = \"$median(D_{frac})$\"\n","    \n","    show_img(image, mnmx, newmnmx=newmnmx, handler=False, title=f'{letter_dim}={mfds[ii]:.6f}', savename=f'{output_path}/train/lossmap_zoom{ii}.png')\n","    plt.tight_layout()\n"]},{"cell_type":"markdown","metadata":{"id":"-GKd1BHeqKjX"},"source":["## Test images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zqiVg3zEYFth"},"outputs":[],"source":["mfds = estimate_fractal_dimension(testimg_history, saveas=f'{output_path}/test/mfd.png')"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["plt.close('all')\n","\n","for ii, impair in enumerate(testimg_history):\n","    image, mnmx = impair\n","    newmnmx = None\n","    if ii < len(testimg_history)-1:\n","        newmnmx = testimg_history[ii+1][1]\n","    str_ii = f\"{ii:02}\"\n","    letter_dim = \"$median(D_{frac})$\"\n","    \n","    show_img(image, mnmx, newmnmx=newmnmx, handler=False, title=f'{letter_dim}={mfds[ii]:.6f}', savename=f'{output_path}/test/lossmap_zoom{ii}.png')\n","    plt.tight_layout()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# plt.close('all')\n","\n","# for ii, impair in enumerate(testimg_history):\n","#     image, mnmx = impair\n","#     newmnmx = None\n","#     if ii < len(testimg_history)-1:\n","#         newmnmx = testimg_history[ii+1][1]\n","#     str_ii = f\"{ii:02}\"    \n","#     show_img(image, mnmx, newmnmx=newmnmx, handler=False, savename=f'{output_path}/test/lossmap_zoom{ii}.png')\n","#     mfd_pngname = f\"{output_path}/test/mfd_zoom{ii}.png\"\n","#     # fractal_dim = f\"{estimate_fractal_dimension(testimg_history[:ii], saveas=mfd_pngname):.5f}\" if ii > 0 else \"NaN\"\n","#     if ii > 0:\n","#         fractal_dim = f\"{estimate_fractal_dimension(testimg_history[:ii+1], saveas=mfd_pngname):.5f}\"\n","#         if ii == len(testimg_history)-1:\n","#             fractal_dim = f\"{estimate_fractal_dimension(testimg_history, saveas=mfd_pngname):.5f}\"\n","#     else:\n","#         fractal_dim = \"NaN\"\n","#     plot_mnmx = truncate_sci_notation(10. ** np.array(mnmx))\n","#     plt.title(f\"fractal dim={fractal_dim} [{plot_mnmx[0]}, {plot_mnmx[1]}]\")\n","#     plt.tight_layout()\n","    \n","# mfd_pngname = f\"{output_path}/test/mfd_zoom{len(testimg_history)}.png\"\n","# estimate_fractal_dimension(testimg_history, saveas=mfd_pngname)"]},{"cell_type":"markdown","metadata":{"id":"GrW2rUkvqr_4"},"source":["# Generate a movie"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xwP2VoByqucJ"},"outputs":[],"source":["train_hist_video = zoom_out_sequence(trainimg_history[-1], growth_factor=2.)\n","test_hist_video = zoom_out_sequence(testimg_history[-1], growth_factor=2.)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RpZGes88YFth"},"outputs":[],"source":["train_hist_video[0][0][0].shape"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FGuXHVwoq1I4"},"outputs":[],"source":["# each call to increase_resolution increases the resolution of one image and\n","# returns True, or returns False if all images are at or exceed the target resolution\n","while increase_resolution(train_hist_video, test_hist_video, 8):\n","    with open(f'{output_path}/train/{canonical_name(None)}.pickle', 'wb') as handle:\n","        pickle.dump(train_hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","    with open(f'{output_path}/test/{canonical_name(None)}.pickle', 'wb') as handle:\n","        pickle.dump(test_hist_video, handle, protocol=pickle.HIGHEST_PROTOCOL)\n","\n","ts = 30\n","# train animation\n","anim = make_animator(train_hist_video, timesteps_per_transition=ts*2)\n","anim.save(f'{output_path}/train/{canonical_name(None)}.mp4',fps=ts, dpi=dpi)\n","#test animation\n","anim = make_animator(test_hist_video, timesteps_per_transition=ts*2)\n","anim.save(f'{output_path}/test/{canonical_name(None)}.mp4',fps=ts, dpi=dpi)\n","\n","# officially end\n","plt.close('all')\n","send_alram(\"Finally all over!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K4Zzh6g6YFth"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":0}
